{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Importing PYSPARK and the most used libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAppName(\"CountingSheep\")\n",
    "spark_context = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, BooleanType\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark import SQLContext\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import enum\n",
    "import time\n",
    "import copy\n",
    "from math import sqrt, atan, floor, ceil\n",
    "spark.sparkContext._conf.getAll()\n",
    "spark.sparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
    "import sys\n",
    "spark.sparkContext.setSystemProperty('spark.executor.heartbeatInterval', '30s')\n",
    "spark.sparkContext.setSystemProperty('spark.network.timeout ', '360s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SERIAL FUNCTIONS OF THE SKYLINE QUERIES\n",
    "def bnl_skyline(data,weights = [1,1,1,1,1,1]):\n",
    "    result = []\n",
    "    islist = True\n",
    "    if isinstance(data,list):\n",
    "        True    \n",
    "    else:\n",
    "        data = list(data)\n",
    "    stopFirst = min(len(weights), len(data[0]))\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    \n",
    "    data_copy = list(data)\n",
    "    for ps in data:\n",
    "        #potential skyline\n",
    "        insert = True\n",
    "        for subset in [result,data_copy]:\n",
    "            for other in subset:\n",
    "                # if it is dominated but does not dominate the datapoint then it is not a skyline point\n",
    "                # if it is not dominated ever it is a skyline point\n",
    "                # if it is dominated and also dominates then it is a tie and it can be a skyline point\n",
    "                isDominated = False\n",
    "                dominates = False\n",
    "                for i in stopFirstArray:\n",
    "                    if ps[i] < other[i] :\n",
    "                        dominates = True\n",
    "                    if ps[i] > other[i] :\n",
    "                        isDominated = True\n",
    "                if isDominated and not dominates :\n",
    "                    insert = False\n",
    "                    break\n",
    "            if not insert:\n",
    "                break\n",
    "        data_copy.remove(ps)\n",
    "        if insert:\n",
    "                result.append(ps)  \n",
    "    return result \n",
    "def nl_skyline(data,weights = [1,1,1,1,1,1]):\n",
    "    result = []\n",
    "    islist = True\n",
    "    if isinstance(data,list):\n",
    "        True    \n",
    "    else:\n",
    "        data = list(data)\n",
    "    stopFirst = min(len(weights), len(data[0]))\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in data:\n",
    "        #potential skyline\n",
    "        insert = True\n",
    "        for other in data:\n",
    "            # if it is dominated but does not dominate the datapoint then it is not a skyline point\n",
    "            # if it is not dominated ever it is a skyline point\n",
    "            # if it is dominated and also dominates then it is a tie and it can be a skyline point\n",
    "            isDominated = False\n",
    "            dominates = False\n",
    "            for i in stopFirstArray:\n",
    "                if ps[i] < other[i] :\n",
    "                    dominates = True\n",
    "                if ps[i] > other[i] :\n",
    "                    isDominated = True\n",
    "            if isDominated and not dominates :\n",
    "                insert = False\n",
    "                break\n",
    "        if insert :\n",
    "                result.append(ps)\n",
    "                \n",
    "    return result \n",
    "\n",
    "# SFS QUERY WITH SORTING\n",
    "def sfs_query_serial(data, weights = [1,1,1,1,1,1,1,1]):\n",
    "    values = []\n",
    "    if not isinstance(data,list):\n",
    "        data = list(data)\n",
    "    # if data is empty\n",
    "    if not data:\n",
    "        return []\n",
    "    stopFirst = min(len(weights), len(data[0]))\n",
    "    data.sort()\n",
    "    nd = []\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in data:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for other in nd:\n",
    "            dominated = False\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < other[k] :\n",
    "                    dominated = True # other point is dominated\n",
    "                    break\n",
    "            if dominated == True:\n",
    "                continue\n",
    "            add = False # default case is when\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    return nd\n",
    "\n",
    "# SFS QUERY WITHOUT SORTING\n",
    "def sfs_query(data, weights = [1,1,1,1,1,1,1,1]):\n",
    "    values = []\n",
    "    nd = []\n",
    "    islist = True\n",
    "    stopFirst = 1\n",
    "    if isinstance(data,map):\n",
    "        mapValue = next(data)\n",
    "        islist = False\n",
    "        stopFirst = min(len(weights), len(mapValue))\n",
    "        nd.append(mapValue)\n",
    "    elif data:\n",
    "        stopFirst = min(len(weights), len(data[0]))\n",
    "\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in data:\n",
    "        # ps : potentially non dominated point\n",
    "        # ps = data[i]\n",
    "        add = True\n",
    "        for other in nd:\n",
    "            dominated = False\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < other[k] :\n",
    "                    dominated = True\n",
    "                    break\n",
    "            if dominated == True:\n",
    "                continue\n",
    "            add = False\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    return nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data generation configuration\n",
    "\n",
    "# Type of dataset generation\n",
    "class DataGenEnum(enum.Enum):\n",
    "    antiCorrelated = 1\n",
    "    anticorrelated = 1\n",
    "    Anticorrelated = 1\n",
    "    AntiCorrelated = 1\n",
    "    correlated = 2\n",
    "    Correlated = 2\n",
    "    Independent = 3\n",
    "    independent = 3\n",
    "    \n",
    "    \n",
    "class DataGenConfig():\n",
    "    def __init__(self, typeOfCorrelation = DataGenEnum.independent, \n",
    "                 dataRange = [0,1], avg = 0.5, skylinePercentage = 1,\n",
    "                 numberOfData = 10**6, numberOfDimensions = 4,\n",
    "                 spreadPercentage = 10): \n",
    "        self.typeOfCorrelation = typeOfCorrelation\n",
    "        self.dataRange = dataRange\n",
    "        # UNUSED Variable\n",
    "        self.avg = avg\n",
    "        self.skylinePercentage = skylinePercentage\n",
    "        self.numberOfData = numberOfData\n",
    "        self.numberOfDimensions = numberOfDimensions\n",
    "        self.spreadPercentage = spreadPercentage\n",
    "        \n",
    "    def setCorrelated(self):\n",
    "            self.typeOfCorrelation = DataGenEnum.correlated\n",
    "    def setAntiCorrelated(self):\n",
    "            self.typeOfCorrelation = DataGenEnum.antiCorrelated\n",
    "    def setIndependent(self):\n",
    "            self.typeOfCorrelation = DataGenEnum.independent \n",
    "            \n",
    "    def setNumberOfData(self, numData):\n",
    "        self.numberOfData = numData\n",
    "    \n",
    "# Method that  creates the different types of datasets based on the distribution   \n",
    "def dataGenerator(dataConfiguration = None):\n",
    "    if dataConfiguration == None :\n",
    "        dataConfiguration = DataGenConfig()\n",
    "        \n",
    "    typeOfCorrelation = dataConfiguration.typeOfCorrelation\n",
    "    dataRange = dataConfiguration.dataRange\n",
    "    avg = dataConfiguration.avg\n",
    "    skylinePercentage = dataConfiguration.skylinePercentage\n",
    "    numberOfData = dataConfiguration.numberOfData\n",
    "    numberOfDimensions = dataConfiguration.numberOfDimensions\n",
    "    spreadPercentage = dataConfiguration.spreadPercentage\n",
    "    \n",
    "    minDataValue = dataRange[0]\n",
    "    maxDataValue = dataRange[1]\n",
    "    data = []\n",
    "    if typeOfCorrelation == DataGenEnum.independent:\n",
    "        for i in range(numberOfData):\n",
    "            datum = []\n",
    "            for i in range(numberOfDimensions):\n",
    "                datum.append(random.random()*(maxDataValue-minDataValue)+minDataValue)\n",
    "            data.append(datum)\n",
    "    elif typeOfCorrelation == DataGenEnum.correlated:\n",
    "        for i in range(numberOfData):\n",
    "            datum = []\n",
    "            datum.append(random.random()*(maxDataValue-minDataValue)+minDataValue)\n",
    "            relatedValue = datum[0]\n",
    "            spread = spreadPercentage * 0.01\n",
    "            for i in range(1, numberOfDimensions):\n",
    "                datum.append(relatedValue + ((random.random()-0.5)*spread) )\n",
    "            data.append(datum)\n",
    "    else: #typeOfCorrelation = antiCorrelated\n",
    "        for i in range(numberOfData):\n",
    "            datum = []\n",
    "            datum.append(random.random()*(maxDataValue-minDataValue)+minDataValue)\n",
    "            relatedValue = maxDataValue-datum[0]\n",
    "            spread = spreadPercentage * 0.01\n",
    "            for i in range(1, numberOfDimensions):\n",
    "                datum.append(relatedValue + (relatedValue*(random.random()-0.5)*spread) )\n",
    "            data.append(datum)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container Object\n",
    "class Result:\n",
    "    def __init__(self, resultList, timeTaken, otherObject = []):\n",
    "        self.resultList = resultList\n",
    "        self.timeTaken = timeTaken\n",
    "        self.otherObject = otherObject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel implementations of SKYLINE QUERIES with fair partitioning methods.\n",
      "Such as random partitioning of poitns or sorting and then partitioning points\n"
     ]
    }
   ],
   "source": [
    "## Parallel implementations of SKYLINE QUEREIS without grid or angular partitioning\n",
    "print('Parallel implementations of SKYLINE QUERIES with fair partitioning methods.\\nSuch as random partitioning of poitns or sorting and then partitioning points')\n",
    "def execute_sfs(input_list, dimensions):\n",
    "    i = 0\n",
    "    allTuplesList = []\n",
    "    newTupleAsList = []\n",
    "    nd  = []\n",
    "    # creation of tuples could be parallelized by glom, although we do not know the length of the list\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i == dimensions:\n",
    "                i = 0\n",
    "                allTuplesList.append( tuple(newTupleAsList) )\n",
    "                newTupleAsList = []\n",
    "            newTupleAsList.append(el)\n",
    "            i = i+1\n",
    "    allTuplesList.append( tuple(newTupleAsList) )\n",
    "    localSky = sfs_query_serial(allTuplesList)\n",
    "    return localSky\n",
    "\n",
    "def parallel_sfs(dataAsList, numberOfSlices = -1, show = False, sort = True):\n",
    "    if numberOfSlices <= 0:\n",
    "        numberOfSlices = min(max(8,  ceil((sys.getsizeof(dataAsList)/1024/1000) * 0.4 ) ), 24)\n",
    "    print('NumSlices: ' + str(numberOfSlices))\n",
    "    numColumns = len(dataAsList[0])\n",
    "    start = time.time()\n",
    "    initialResult = spark.sparkContext.parallelize(dataAsList, numberOfSlices).sortBy(lambda x: x[0]).mapPartitions(sfs_query)\n",
    "    initialResult = initialResult.collect()\n",
    "    end = time.time()-start\n",
    "    \n",
    "    print('Length of first pass of parallel sfs is: ' + str(len(initialResult)))\n",
    "    print('Time taken by the parallel section of SFS: ' + str(end))\n",
    "    initialResult = [list(x) for x in initialResult ]\n",
    "    start_serial = time.time()\n",
    "    finSky = sfs_query_serial(initialResult)\n",
    "    end_serial = time.time() - start_serial\n",
    "    print('Length of the skyline: ' + str(len(finSky)))\n",
    "    print('Time taken by the serial section of SFS: ' + str(end_serial))\n",
    "    print('Time taken in total for SFS execution: ' + str(end_serial+end))\n",
    "    if show :\n",
    "        helperVisualFunct(ddbb)\n",
    "        helperVisualFunct(finSky,'Parallel sfs skyline')\n",
    "        plt.show()\n",
    "        if numColumns > 2 :\n",
    "            show3D(ddbb)\n",
    "            show3D(finSky)\n",
    "    res = Result(finSky, end+end_serial)\n",
    "    return res\n",
    "\n",
    "def parallel_sfs_random(dataAsList, numberOfSlices = -1, show = False, sort = True):\n",
    "    if numberOfSlices <= 0:\n",
    "        numberOfSlices = min(max(8,  ceil((sys.getsizeof(dataAsList)/1024/1000) * 0.4 ) ), 24)\n",
    "    print('NumSlices: ' + str(numberOfSlices))\n",
    "    numColumns = len(dataAsList[0])\n",
    "    start = time.time()\n",
    "    initialResult = spark.sparkContext.parallelize(dataAsList, numberOfSlices).mapPartitions(sfs_query_serial)\n",
    "    initialResult = initialResult.collect()\n",
    "    end = time.time()-start\n",
    "    \n",
    "    print('Length of first pass of parallel sfs random is: ' + str(len(initialResult)))\n",
    "    print('Time taken by the parallel section of SFS random: ' + str(end))\n",
    "    initialResult = [list(x) for x in initialResult ]\n",
    "    start_serial = time.time()\n",
    "    finSky = sfs_query_serial(initialResult)\n",
    "    end_serial = time.time() - start_serial\n",
    "    print('Length of the skyline: ' + str(len(finSky)))\n",
    "    print('Time taken by the serial section of SFS random: ' + str(end_serial))\n",
    "    print('Time taken in total for SFS execution random: ' + str(end_serial+end))\n",
    "    if show :\n",
    "        helperVisualFunct(ddbb)\n",
    "        helperVisualFunct(finSky,'Parallel sfs skyline')\n",
    "        plt.show()\n",
    "        if numColumns > 2 :\n",
    "            show3D(ddbb)\n",
    "            show3D(finSky)\n",
    "    res = Result(finSky, end+end_serial)\n",
    "    return res\n",
    "\n",
    "\n",
    "def parallel_bnl(dataAsList, numberOfSlices = 16, show = False):\n",
    "    ddbb = dataAsList\n",
    "    start = time.time()\n",
    "    weights = [1,1,1,1,1,1,1,1,1]\n",
    "    initialResult = spark.sparkContext.parallelize(ddbb, numberOfSlices).mapPartitions(bnl_skyline).collect()\n",
    "    finSky = bnl_skyline(initialResult, weights)\n",
    "    end = time.time()-start\n",
    "    print('Length of first pass of parallel BNL is: ' + str(len(initialResult)))\n",
    "    print('Time taken by the parallel implementation of BNL: ' + str(end))\n",
    "    if show :\n",
    "        helperVisualFunct(ddbb)\n",
    "        helperVisualFunct(finSky,'Parallel sfs skyline')\n",
    "        plt.show()\n",
    "        if len(ddbb[0]) > 2 :\n",
    "            show3D(ddbb)\n",
    "            show3D(finSky)\n",
    "    res = Result(finSky, end)\n",
    "    return res\n",
    "\n",
    "def execute_bnl(input_list, dimensions, weights):\n",
    "    i = 0\n",
    "    allTuplesList = []\n",
    "    newTupleAsList = []\n",
    "    # creation of tuples could be parallelized by glom, although we do not know the length of the list\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i == dimensions:\n",
    "                i = 0\n",
    "                allTuplesList.append( tuple(newTupleAsList) )\n",
    "                newTupleAsList = []\n",
    "            newTupleAsList.append(el)\n",
    "            i = i+1\n",
    "    allTuplesList.append( tuple(newTupleAsList) )\n",
    "    localSky = bnl_skyline(allTuplesList, weights)\n",
    "    return localSky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use DataFrames to create the SQL Query of the skyline\n",
    "# This query benefits from the catalyst optimizer, although RDDs do not\n",
    "# This query performs many times better than RDD implementations for lower data cardinalities\n",
    "def sqlSkyline(dataArray, debug = False):\n",
    "    numColumns = len(dataArray[0])\n",
    "    structFieldArray = []\n",
    "    \n",
    "    for i in range(numColumns):\n",
    "        if type(dataArray[0][i]) == int :\n",
    "            structFieldArray.append(StructField('x'+str(i), IntegerType(),True))\n",
    "        if type(dataArray[0][i]) == float :\n",
    "            structFieldArray.append(StructField('x'+str(i), FloatType(),True))\n",
    "        if type(dataArray[0][i]) == str :\n",
    "            continue\n",
    "        \n",
    "    schema = StructType(structFieldArray)\n",
    "    p = spark.createDataFrame(dataArray, schema = schema)\n",
    "    dataArray = []\n",
    "    if debug == True:\n",
    "        p.show()\n",
    "    p.createOrReplaceTempView(\"Z1\")\n",
    "    condition = ''\n",
    "    for i in range(numColumns):\n",
    "        condition = condition + 'p1.x' + str(i) + '<=p.x' + str(i) + ' AND '\n",
    "    condition = condition + '('\n",
    "    for i in range(numColumns):\n",
    "        if i != numColumns -1 :\n",
    "            condition =condition + 'p1.x' + str(i) + '<p.x' + str(i) + ' OR '\n",
    "        else : \n",
    "            condition = condition + 'p1.x' + str(i) + '<p.x' + str(i) + ') )'\n",
    "    \n",
    "    sqlQuery = 'SELECT * FROM Z1 p WHERE NOT EXISTS(SELECT * FROM Z1 p1 WHERE ' + condition\n",
    "    # The query here is : \n",
    "    # SELECT * FROM Z1 p WHERE NOT EXISTS\n",
    "    #                                    (SELECT * FROM Z1 p1 WHERE p1.x1 <= p.x1 AND p1.x2 <= p.x2 AND etc.. AND\n",
    "    #                                                     (p1.x1 < p.x1 OR p1.x2 < p.x2 OR etc.. ) ) \n",
    "    start = time.time()\n",
    "    partialRes = spark.sql(sqlQuery)\n",
    "    points = partialRes.collect()\n",
    "    end = time.time() - start\n",
    "    if debug == True:\n",
    "        print(sqlQuery)\n",
    "        partialRes.show()\n",
    "    print('Time taken by the SQL Query: ' + str(end))\n",
    "    \n",
    "    p.unpersist()\n",
    "    spark.catalog.dropTempView(\"Z1\")\n",
    "    return Result(points, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive angular partitioning\n"
     ]
    }
   ],
   "source": [
    "# Angular partitioning\n",
    "print('Naive angular partitioning')\n",
    "# calculate index\n",
    "def getPartitionIndex(datapoint, dimensions, numSlices = 16):\n",
    "    angleSQ = 0\n",
    "    for i in range(dimensions):\n",
    "        angleSQ = angleSQ + datapoint[i]**2\n",
    "        \n",
    "    anglesArray = []\n",
    "    ## first is radius then all angles\n",
    "    for i in range(dimensions):\n",
    "        if i == 0:\n",
    "            # radius\n",
    "            continue\n",
    "        else:\n",
    "            angleSQ = angleSQ - (datapoint[i-1]**2) \n",
    "            angleSQ = max(0,angleSQ)\n",
    "            if datapoint[i-1] == 0:\n",
    "                value = sqrt(angleSQ) / (0.0001)\n",
    "            else:\n",
    "                value = sqrt(angleSQ) /  datapoint[i-1]\n",
    "        anglesArray.append(value)\n",
    "    radToDeg = 57.2957795\n",
    "    piHalf = 1.57\n",
    "    twoByPi = 0.636619772\n",
    "    index = 0\n",
    "    twoByPiNumSlices = twoByPi*numSlices\n",
    "    for i in range(len(anglesArray)):\n",
    "        index = index + floor(atan(anglesArray[i])*twoByPiNumSlices) * (numSlices**i)\n",
    "    return index\n",
    "\n",
    "#unpack each data by it's first index\n",
    "def execute_sfs_indexed(input_list, dimensions, weights):\n",
    "    i = 0\n",
    "    newList = []\n",
    "    nd = []\n",
    "    isFirst = True\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i % 2 == 1:\n",
    "                ps = el\n",
    "                nd.append(ps)\n",
    "            i = i + 1\n",
    "    nd = sfs_query_serial(nd,[1,1,1,1,1,1,1,1])\n",
    "    return nd\n",
    "\n",
    "def execute_sfs_serial(input_list, dimensions, weights):\n",
    "    i = 0\n",
    "    allTuplesList = []\n",
    "    newTupleAsList = []\n",
    "    nd  = []\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i == dimensions:\n",
    "                i = 0\n",
    "                allTuplesList.append( tuple(newTupleAsList) )\n",
    "                newTupleAsList = []\n",
    "            newTupleAsList.append(el)\n",
    "            i = i+1\n",
    "    allTuplesList.append( tuple(newTupleAsList) )\n",
    "    localSky = sfs_query_serial(allTuplesList, weights)\n",
    "    return localSky\n",
    "    \n",
    "def parallel_angled_partitioning(dataArray, numSlices = 16):\n",
    "    print('AP: Number of slices : ' + str(numSlices))\n",
    "    dimensions = len(dataArray[0])\n",
    "    weights = [1,1,1,1,1,1]\n",
    "    start = time.time()\n",
    "    # Partition By divides the dataset by the primary key of each tuple\n",
    "    m2 = spark.sparkContext.parallelize(dataArray, numSlices) \\\n",
    "                    .map(lambda x : ( getPartitionIndex(x,dimensions,numSlices)  , x) )  \\\n",
    "                    .partitionBy(numSlices**(dimensions-1)) \\\n",
    "                    .mapPartitions(lambda x : execute_sfs_indexed(x, dimensions, weights), preservesPartitioning=True)  \\\n",
    "                    .collect()\n",
    "    end = time.time()- start\n",
    "    print('Time taken for parallel section in AP: ' + str(end))\n",
    "    print('AP: Length of initial Pass is :' + str(len(m2)))\n",
    "    seq_time = time.time()\n",
    "    finRes = sfs_query_serial(m2, weights)\n",
    "    end_seq = time.time() - seq_time\n",
    "\n",
    "    print('AP: Length of the skyline is :' + str(len(finRes)))\n",
    "    print('AP: Sequential time taken: ' + str(end_seq))\n",
    "    print('AP: Total Time: ' + str(end+end_seq))\n",
    "    return Result(finRes,end+end_seq)\n",
    "\n",
    "\n",
    "def sfs_query_with_memory(data, memory, weights = [1,1,1,1,1,1,1,1]):\n",
    "    values = []\n",
    "    nd = memory\n",
    "    stopFirst = min(len(weights), len(memory[0]))\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in data:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for other in nd:\n",
    "            dominated = False\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < other[k] :\n",
    "                    dominated = True # other point is dominated\n",
    "                    break\n",
    "            if dominated == True:\n",
    "                continue\n",
    "            add = False # default case is when\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    return nd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid partitioning with a serial grid filtering phase\n"
     ]
    }
   ],
   "source": [
    "# Grid partitioning\n",
    "print('Grid partitioning with a serial grid filtering phase')\n",
    "class Container:\n",
    "    def __init__(self, pointFound = [], dataContained = []):\n",
    "        self.pointFound = pointFound\n",
    "        self.dataContained = dataContained\n",
    "        \n",
    "    def addPoint(self, dataPoint):\n",
    "        if len(dataPoint) != len(pointFound):\n",
    "            raise Exception('Datapoint dimension not consistent with container point`s dimensions: ' \\\n",
    "                            + str(len(dataPoint)) + \\\n",
    "                            ' ' + len(pointFound))\n",
    "        dataContained.add(dataPoint)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize_data(data):\n",
    "    return ( 0.999999*(data - np.min(data))) / (np.max(data) - np.min(data)).tolist()\n",
    "        \n",
    "def sfs_query_for_containers(containerList, weights=[1,1,1,1,1,1,1]):\n",
    "    stopFirst = min(len(weights),len(containerList[0].pointFound))\n",
    "    nd = []\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for i in range(len(containerList)):\n",
    "        if not containerList[i].dataContained: #if dataContained array is not empty\n",
    "            continue\n",
    "        # ps : potentially non dominated point\n",
    "        ps = containerList[i].pointFound\n",
    "        add = True\n",
    "        for other in nd:\n",
    "            dominated = False\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] <= other.pointFound[k] :\n",
    "                    dominated = True\n",
    "                    break\n",
    "            if dominated == True:\n",
    "                continue\n",
    "            add = False\n",
    "        if add == True:\n",
    "            ps = containerList[i]\n",
    "            nd.append(ps)\n",
    "    return nd        \n",
    "\n",
    "# Finds the skyline of grid containers based on its representative point\n",
    "def query_containers(datapoints, dimensions, numSlicesPerDimension = 8, initialStepLen = -1):\n",
    "    if initialStepLen == -1:\n",
    "        initialStepLen = len(datapoints)\n",
    "    limit = 1 / (numSlicesPerDimension)\n",
    "    print('iterating - limit: ' +str(limit))\n",
    "    num_slices_in_space = numSlicesPerDimension**dimensions\n",
    "    containerList = []\n",
    "    # create N square containers with each container having the datapoints contained and an index\n",
    "    range_dim = range(dimensions)\n",
    "    for i in range(num_slices_in_space): \n",
    "        point = []\n",
    "        for j in range_dim:\n",
    "            index = floor( i / (numSlicesPerDimension**j) ) % numSlicesPerDimension\n",
    "            point.insert(j, index * limit + limit)\n",
    "        containerList.insert(i+1, Container(point, []))\n",
    "        \n",
    "    for dp in datapoints:\n",
    "        index = 0\n",
    "        for i in range(len(dp)):\n",
    "            if dp[i] >= 1:\n",
    "                index = index + floor(0.99999 / limit) * (numSlicesPerDimension**i)\n",
    "            else:\n",
    "                index = index + floor(dp[i] / limit) * (numSlicesPerDimension**i)\n",
    "        (containerList[index].dataContained).append(dp)\n",
    "    resultingContainers = sfs_query_for_containers(containerList)\n",
    "    input_list = []\n",
    "    for container in resultingContainers:\n",
    "        input_list = input_list + container.dataContained\n",
    "    if len(input_list) <= initialStepLen * 0.80 :\n",
    "        # if we discarded 20% of the previous step list's length then we do another step\n",
    "        input_list = query_containers(normalize_data(input_list), dimensions, numSlicesPerDimension, len(input_list))\n",
    "    return input_list\n",
    "\n",
    "# Works for normalized data [0,1) only \n",
    "# Grid partitioning but with a serial filtering phase \n",
    "def sfs_index_squares(datapoints, dimensions = -1, numSlicesPerDimension = 12):\n",
    "    if dimensions == -1:\n",
    "        dimensions = len(datapoints[0])\n",
    "    if numSlicesPerDimension <= 1:\n",
    "        if dimensions <= 4:\n",
    "            numSlicesPerDimension = 12\n",
    "        else:\n",
    "            numSlicesPerDimension = 5\n",
    "    start = time.time()\n",
    "    input_list = query_containers(datapoints, dimensions, numSlicesPerDimension)\n",
    "    end = time.time() - start\n",
    "    print(str(end) + ' for the container serial query')\n",
    "    print('After first pass list length: ' + str(len(input_list)))\n",
    "    print('After first pass list Size: ' + str(sys.getsizeof(input_list)/1024) + 'KB')\n",
    "    numSlices = 12\n",
    "    print('Num slices has been decided to be: ' + str(numSlices))\n",
    "    start_parallel = time.time()\n",
    "    finalResult = parallel_sfs(input_list, numSlices)\n",
    "    end_parallel = time.time() - start_parallel\n",
    "    print(str(end_parallel) + ' for the parallel_sfs query')\n",
    "    print(str(end_parallel+end) + ' = total')\n",
    "    return Result(finalResult.resultList, end_parallel+end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius partitioning with succesive angular partitioning skyline query\n"
     ]
    }
   ],
   "source": [
    "# Radius Partitioning\n",
    "print('Radius partitioning with succesive angular partitioning skyline query')\n",
    "def sfs_query_serial_with_memory(data, memory, weights = [1,1,1,1,1,1,1,1]):\n",
    "    values = []\n",
    "    mergeSort(data)\n",
    "    nd = memory\n",
    "    stopFirst = min(len(weights), len(memory[0]))\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in data:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for other in nd:\n",
    "            dominated = False\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < other[k] :\n",
    "                    dominated = True # other point is dominated\n",
    "                    break\n",
    "            if dominated == True:\n",
    "                continue\n",
    "            add = False # default case is when\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    return nd\n",
    "\n",
    "def execute_sfs_indexed_with_memory(input_list, memory_list):\n",
    "    i = 0\n",
    "    newList = []\n",
    "    allTuples = []\n",
    "    isFirst = True\n",
    "    indexKey = 0\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i % 2 == 1:\n",
    "                ps = el\n",
    "                allTuples.append(ps)\n",
    "            i = i + 1\n",
    "    nd = sfs_query_serial_with_memory(allTuples, memory_list,[1,1,1,1,1,1,1,1])\n",
    "    return nd\n",
    "    \n",
    "def find_in_radius(input_list, dimensions, beginning = 0.0 ,radius = 0.2):\n",
    "    angleSQ = 0\n",
    "    i = 0\n",
    "    point_radius = 0\n",
    "    squared_radius = radius * radius\n",
    "    squared_beginning = beginning * beginning\n",
    "    newTupleAsList = []\n",
    "    allTuplesList = []\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            newTupleAsList.append(el)\n",
    "            point_radius = point_radius + (el * el)\n",
    "            i = i+1\n",
    "            if i == dimensions:\n",
    "                i = 0\n",
    "                if point_radius <= squared_radius and squared_beginning <= point_radius: \n",
    "                    allTuplesList.append( tuple(newTupleAsList) )\n",
    "                newTupleAsList = []\n",
    "                point_radius = 0\n",
    "    if point_radius <= squared_radius and squared_beginning <= point_radius: \n",
    "        allTuplesList.append( tuple(newTupleAsList) )\n",
    "    allTuplesList = [x for x in allTuplesList if x]\n",
    "    return allTuplesList\n",
    "    \n",
    "def parallel_radius_partitioning(dataArray, radius = 0.5, numSlices = 16):\n",
    "    dimensions = len(dataArray[0])\n",
    "    weights = [1,1,1,1,1,1,1]\n",
    "    start_1 = time.time()\n",
    "    dataArray = NormalizeData(dataArray).tolist()\n",
    "    # we get the first few datapoints that have a lot of weight, being inside the unit circle\n",
    "    m1 = spark.sparkContext.parallelize(dataArray, numSlices) \\\n",
    "                    .mapPartitions(lambda x : find_in_radius(x, dimensions, beginning = 0, radius = radius)) \\\n",
    "                    .collect()\n",
    "    m1 = spark.sparkContext.parallelize(m1, numSlices) \\\n",
    "                    .sortBy(lambda x: x[0])\\\n",
    "                    .mapPartitions(sfs_query) \\\n",
    "                    .collect()\n",
    "    # we pass these datapoints to every parallel logic unit so that they can filter skyline points better\n",
    "    end_1 = time.time() - start_1\n",
    "    start = time.time()\n",
    "    m2 = spark.sparkContext.parallelize(dataArray, numSlices) \\\n",
    "                    .mapPartitions(lambda x : find_in_radius(x, dimensions, beginning = radius,radius = 2))  \\\n",
    "                    .map(lambda x : (getPartitionIndex(x,len(x),numSlices),x))  \\\n",
    "                    .partitionBy(numSlices) \\\n",
    "                    .mapPartitions(lambda x : \\\n",
    "                                   execute_sfs_indexed_with_memory(x, m1), preservesPartitioning=True)  \\\n",
    "                    .collect()\n",
    "    end = time.time() - start\n",
    "    seq_time = time.time()\n",
    "    finRes = sfs_query_serial(m2, weights)\n",
    "    end_seq = time.time() - seq_time\n",
    "\n",
    "    print('Length of 1st Pass is :' + str(len(m1)))\n",
    "    print('Length of 2nd Pass is :' + str(len(m2)))\n",
    "    print('Length of the skyline :' + str(len(finRes)))\n",
    "    print('Time taken in parallel section 1st pass: ' + str(end_1))\n",
    "    print('Time taken in parallel section 2nd pass: ' + str(end))\n",
    "    print('Sequential time taken: ' + str(end_seq))\n",
    "    print('Total Time: ' + str(end+end_seq+end_1))\n",
    "    return Result(finRes,end+end_seq+end_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper methods for Representative filtering.\n"
     ]
    }
   ],
   "source": [
    "print('Helper methods for Representative filtering.')\n",
    "def get_best_representatives(index, dataset, n = 30):\n",
    "    # index is the dimension which we should check\n",
    "    # is a tuple with area_covered as the first element and the n-dimensional point as the second element\n",
    "    best_n_points = []\n",
    "    limit = 1/n # default is 0.01\n",
    "    for i in range(n):\n",
    "        best_n_points.append((0,[]))\n",
    "    counter = 0\n",
    "    for point in dataset:\n",
    "        counter = counter + 1\n",
    "        area_covered = 1\n",
    "        for element in point:\n",
    "            area_covered = area_covered * (1-element)\n",
    "        rep_index = floor(point[index]/limit)\n",
    "        if best_n_points[rep_index][0] < area_covered:\n",
    "            best_n_points[rep_index] = (area_covered, point)\n",
    "    best_n_points = [x[1] for x in best_n_points if x[1]]\n",
    "    return best_n_points\n",
    "\n",
    "\n",
    "def filter_with_memory(datapoints, reps, onlyFilter = False):\n",
    "    values = []\n",
    "    nd = []\n",
    "    stopFirst = len(reps[0])\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    for ps in datapoints:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for rep in reps:\n",
    "            dominated = False\n",
    "            eq_dim = 0\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < rep[k] :\n",
    "                    dominated = True # other point is dominated\n",
    "                    break\n",
    "                elif ps[k] == rep[k]:\n",
    "                    eq_dim = eq_dim + 1\n",
    "            if dominated == True or eq_dim == stopFirst:\n",
    "                continue\n",
    "            add = False # default case is when\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    if onlyFilter:\n",
    "        return nd\n",
    "    return sfs_query(nd)\n",
    "\n",
    "\n",
    "def execute_sfs_no_sort(input_list, dimensions):\n",
    "    i = 0\n",
    "    allTuplesList = []\n",
    "    newTupleAsList = []\n",
    "    nd  = []\n",
    "    # creation of tuples could be parallelized by glom, although we do not know the length of the list\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i == dimensions:\n",
    "                i = 0\n",
    "                allTuplesList.append( tuple(newTupleAsList) )\n",
    "                newTupleAsList = []\n",
    "            newTupleAsList.append(el)\n",
    "            i = i+1\n",
    "    allTuplesList.append( tuple(newTupleAsList) )\n",
    "    allTuplesList.sort(key=lambda x: x[0])\n",
    "    localSky = sfs_query(allTuplesList)\n",
    "    return localSky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFS Query with Representative filtering.\n"
     ]
    }
   ],
   "source": [
    "# PARALLEL SFS With Representative filtering\n",
    "print('SFS Query with Representative filtering.')\n",
    "def parallel_sfs_with_representatives(dataAsList, slicesForSorting = -1, onlyFilter = False, givenReps = [], numberReps = 30):\n",
    "    if slicesForSorting < 0:\n",
    "        slicesForSorting = 12\n",
    "    print('Slices for representative skyline ' + str(slicesForSorting))\n",
    "    start_indexing = time.time()\n",
    "    if givenReps == []:\n",
    "        representatives = spark.sparkContext.parallelize(dataAsList, len(dataAsList[0]) ) \\\n",
    "                                    .mapPartitionsWithIndex(lambda index, y: get_best_representatives(index, y, n = numberReps)) \\\n",
    "                                    .collect()\n",
    "    else:\n",
    "        representatives = givenReps\n",
    "    end_indexing = time.time() - start_indexing\n",
    "    print('Time taken to find best reps ' + str(end_indexing))\n",
    "    print('Length of representatives: ' + str(len(representatives)))\n",
    "    representatives = sfs_query_serial(representatives)\n",
    "    print('Length of representatives after skyline query: ' + str(len(representatives)))\n",
    "    start_parallel = time.time()\n",
    "    parallel_skyline = []\n",
    "    \n",
    "    parallel_skyline = spark.sparkContext.parallelize(dataAsList, slicesForSorting)\\\n",
    "                                .mapPartitions(lambda x : filter_with_memory(x, representatives, onlyFilter = True)) \\\n",
    "                                .collect()\n",
    "    end_parallel = time.time() - start_parallel\n",
    "    \n",
    "    print('Time taken to filter: ' +str(end_parallel))\n",
    "    print('Length of the after filter: ' + str(len(parallel_skyline)))\n",
    "    start = time.time()\n",
    "    parallel_skyline.sort(key=lambda x: x[0])\n",
    "    parallel_skyline = spark.sparkContext.parallelize(parallel_skyline, slicesForSorting)\\\n",
    "                            .mapPartitions(lambda x : execute_sfs_no_sort(x, len(parallel_skyline[0]) )) \\\n",
    "                            .collect()\n",
    "    \n",
    "    end = time.time() - start\n",
    "    \n",
    "    print('Time taken to find the local skylines: ' +str(end))\n",
    "    print('Length of parallel skyline: ' + str(len(parallel_skyline)))\n",
    "    print('Final Serial stage:')\n",
    "    start_serial = time.time()\n",
    "    finRes = sfs_query_serial(parallel_skyline)\n",
    "    end_serial = time.time() - start_serial\n",
    "    print('~~~~~ Time taken to find the global skyline : ' +str(end_serial))\n",
    "    print('~~~~~ Length of the skyline: ' + str(len(finRes)))\n",
    "    print('~~~~~ Total time taken with representatives: ' + str(end_serial+end_parallel+end_indexing+end))\n",
    "    return Result(finRes,end_serial+end_parallel+end_indexing+end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFS Query with Representative filtering and/or parallel global skyline computation\n"
     ]
    }
   ],
   "source": [
    "# SFS Query with representatives\n",
    "print('SFS Query with Representative filtering and/or parallel global skyline computation')\n",
    "def get_best_representatives(index, dataset, n = 10):\n",
    "    # index is the dimension which we should check\n",
    "    # is a tuple with area_covered as the first element and the n-dimensional point as the second element\n",
    "    best_n_points = []\n",
    "    limit = 1/n # default is 0.01\n",
    "    for i in range(n):\n",
    "        best_n_points.append((0,[]))\n",
    "    counter = 0\n",
    "    for point in dataset:\n",
    "#         if counter > 20000:\n",
    "#             break\n",
    "        counter = counter + 1\n",
    "        area_covered = 1\n",
    "        for element in point:\n",
    "            area_covered = area_covered * (1-element)\n",
    "        rep_index = floor(point[index]/limit)\n",
    "        if best_n_points[rep_index][0] < area_covered:\n",
    "            best_n_points[rep_index] = (area_covered, point)\n",
    "    best_n_points = [x[1] for x in best_n_points if x[1]]\n",
    "    return best_n_points\n",
    "def filter_with_memory(datapoints, reps, onlyFilter = False):\n",
    "    values = []\n",
    "    nd = []\n",
    "    stopFirst = len(reps[0])\n",
    "    stopFirstArray = range(stopFirst)\n",
    "    reps = sfs_query_serial(reps)\n",
    "    for ps in datapoints:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for rep in reps:\n",
    "            dominated = False\n",
    "            eq_dim = 0\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < rep[k] :\n",
    "                    dominated = True # other point is dominated\n",
    "                    break\n",
    "                elif ps[k] == rep[k]:\n",
    "                    eq_dim = eq_dim + 1\n",
    "            if dominated == True or eq_dim == stopFirst:\n",
    "                continue\n",
    "            add = False # default case is when\n",
    "            break\n",
    "        if add == True:\n",
    "            nd.append(ps)\n",
    "    if onlyFilter:\n",
    "        return nd\n",
    "    return sfs_query(nd)\n",
    "\n",
    "\n",
    "def sfs_multithread(datapoints, global_set):\n",
    "    values = []\n",
    "    nd = []\n",
    "    islist = True\n",
    "    stopFirst = len(global_set[0])\n",
    "    #useless \n",
    "    stopFirstArray = range(stopFirst)\n",
    "    datapoints = list(datapoints)\n",
    "    for ps in datapoints:\n",
    "        # ps : potentially non dominated point\n",
    "        add = True\n",
    "        for other in global_set:\n",
    "            # dominated other\n",
    "            dominates = False\n",
    "            # num of dimensions in which the points are equal\n",
    "            dimEqual = 0\n",
    "            for k in stopFirstArray:\n",
    "                if ps[k] < other[k] :\n",
    "                    dominates = True\n",
    "                    break\n",
    "                elif other[k] == ps[k]:\n",
    "                    dimEqual = dimEqual + 1\n",
    "            if dominates == True:\n",
    "                continue\n",
    "            # We suppose that the global_set is ordered. \n",
    "            # Keeping in mind that the global_set is a superset of our datapoints, if we find our point in the global_set\n",
    "            # then all other points can not dominated this current point.\n",
    "            if dimEqual == len(global_set[0]):\n",
    "                nd.append(ps)\n",
    "                break\n",
    "            add = False\n",
    "            break\n",
    "    return nd\n",
    "\n",
    "def parallel_3P(dataAsList, slicesForSorting = -1):\n",
    "    if slicesForSorting < 0:\n",
    "        slicesForSorting = 12\n",
    "    sortedData = []\n",
    "    print('Slices for representative skyline ' + str(slicesForSorting))\n",
    "    start = time.time()\n",
    "    if len(dataAsList) <= 10**5:\n",
    "        mergeSort(dataAsList)\n",
    "        sortedData = dataAsList\n",
    "    else:\n",
    "        sortedData = spark.sparkContext.parallelize(dataAsList, max(12,slicesForSorting)).sortBy(lambda x: x[0]).collect()\n",
    "    end = time.time() - start\n",
    "    print('Time taken for sorting in parallel: '+ str(end))\n",
    "    \n",
    "    start_indexing = time.time()\n",
    "    representatives = spark.sparkContext.parallelize(sortedData, len(dataAsList[0])) \\\n",
    "                                .mapPartitionsWithIndex(lambda index, y: get_best_representatives(index, y)) \\\n",
    "                                .collect()\n",
    "    end_indexing = time.time() - start_indexing\n",
    "    print('Time taken to find best reps ' + str(end_indexing))\n",
    "    print('Length of representatives: ' + str(len(representatives)))\n",
    "\n",
    "    start_parallel = time.time()\n",
    "    parallel_skyline = []\n",
    "    parallel_skyline = spark.sparkContext.parallelize(sortedData, slicesForSorting)\\\n",
    "                                .mapPartitions(lambda x : filter_with_memory(x, representatives)) \\\n",
    "                                .collect()\n",
    "    end_parallel = time.time() - start_parallel\n",
    "    print('Time taken to find the local skylines: ' +str(end_parallel))\n",
    "    print('Length of the parallel section skyline: ' + str(len(parallel_skyline)))\n",
    "    print('~~~~~ Second parallel stage:')\n",
    "    # compare mappartitions vs map        \n",
    "    start_serial = time.time()\n",
    "    parallel_global_skyline = spark.sparkContext.parallelize(parallel_skyline, slicesForSorting)\\\n",
    "                                .mapPartitions(lambda x : sfs_multithread(x,parallel_skyline)) \\\n",
    "                                .collect()    \n",
    "\n",
    "    end_serial = time.time() - start_serial\n",
    "    print('~~~~~ Time taken to find the global skyline (stage 2 parallel): ' +str(end_serial))\n",
    "    print('~~~~~ Length of the skyline: ' + str(len(parallel_global_skyline)))\n",
    "    print('~~~~~ Total time taken with representatives: ' + str(end_serial+end_parallel+end_indexing+end))\n",
    "    return Result(parallel_global_skyline,end_serial+end_parallel+end_indexing+end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive grid partitioning\n"
     ]
    }
   ],
   "source": [
    "# Naive Grid partitioning\n",
    "print('Naive grid partitioning')\n",
    "def get_grid_partition_index(datapoint, dimensions, numSlices = 2):\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(len(datapoint)):\n",
    "        true = True\n",
    "        true = True\n",
    "        # Maps space from 0 to numSlices ^ dimensions - 1\n",
    "        if datapoint[i] >= 1:\n",
    "            index = index + (numSlices-1) * (numSlices**i)\n",
    "        else:\n",
    "            index = index + floor(datapoint[i] * numSlices) * (numSlices**i)\n",
    "    return index\n",
    "\n",
    "#unpack each data by it's first index\n",
    "def execute_sfs_indexed(input_list, dimensions, weights):\n",
    "    i = 0\n",
    "    newList = []\n",
    "    nd = []\n",
    "    for el_list in input_list:\n",
    "        for el in el_list:\n",
    "            if i % 2 == 1:\n",
    "                ps = el\n",
    "                nd.append(ps)\n",
    "            i = i + 1\n",
    "    nd = sfs_query_serial(nd,[1,1,1,1,1,1,1,1])\n",
    "    return nd\n",
    "\n",
    "    \n",
    "def naive_grid_partitioning(dataArray, numSlices = 2):\n",
    "    dimensions = len(dataArray[0])\n",
    "    weights = [1,1,1,1,1,1,1,1]\n",
    "    print('Number of slices := ' + str(numSlices**dimensions))\n",
    "    numSlices = ceil(numSlices**dimensions)\n",
    "    num__ = min(numSlices,32)\n",
    "    start = time.time()\n",
    "    m2 = spark.sparkContext.parallelize(dataArray, num__) \\\n",
    "                    .map(lambda x : ( get_grid_partition_index(x,dimensions,numSlices), x ) )  \\\n",
    "                    .partitionBy(numSlices) \\\n",
    "                    .mapPartitions(lambda x : execute_sfs_indexed(x, dimensions, weights), preservesPartitioning=True) \\\n",
    "                    .collect()\n",
    "    end = time.time()- start\n",
    "    print('Time taken for parallel section in GP: ' + str(end))\n",
    "    print('GP: Length of initial Pass is :' + str(len(m2)))\n",
    "    seq_time = time.time()\n",
    "    finRes = sfs_query_serial(m2, weights)\n",
    "    end_seq = time.time() - seq_time\n",
    "\n",
    "    print('GP: Length of the skyline is :' + str(len(finRes)))\n",
    "    print('GP: Sequential time taken: ' + str(end_seq))\n",
    "    print('GP: Total Time: ' + str(end+end_seq))\n",
    "    return Result(finRes,end+end_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated grid partitioning method with reduction of domination tests. \n",
      "We only test points between containers that can dominate one another.\n"
     ]
    }
   ],
   "source": [
    "# Grid partitioning with \n",
    "print('Updated grid partitioning method with reduction of domination tests. \\n\\\n",
    "We only test points between containers that can dominate one another.')\n",
    "def get_grid_partition_index(datapoint, dimensions, numSlicesPerDimension = 2):\n",
    "    numSlices = numSlicesPerDimension\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(len(datapoint)):\n",
    "        true = True\n",
    "        true = True\n",
    "        # Maps space from 0 to numSlices ^ dimensions - 1\n",
    "        if datapoint[i] >= 1:\n",
    "            index = index + (numSlices-1) * (numSlices**i)\n",
    "        else:\n",
    "            index = index + floor(datapoint[i] * numSlices) * (numSlices**i)\n",
    "    return index\n",
    "\n",
    "def pack_data(data, NSPD):\n",
    "    dataList = list(data)\n",
    "    data = dataList\n",
    "   \n",
    "    # Data example is := when NSPD = 4 => (1, [0.26,0.0]), (1, [0.33,0.11]) and another data := (6, [0.51,0.26])\n",
    "    if data and data[0] and data[0][1]:\n",
    "        dimensions = len(data[0][1]) # equal to NSPD\n",
    "    else:\n",
    "        return []\n",
    "    limit = 1/NSPD\n",
    "    toReturn = True\n",
    "    packing_array = []\n",
    "    for i in range(len(data)):\n",
    "        packing_array.append(data[i][1])\n",
    "    # ( 0, [ [0,0] , [0.1,0.1]] )\n",
    "    return [(data[0][0], packing_array)]\n",
    "\n",
    "def test_square_domination(data, NSPD, packed_sky):\n",
    "    # data is going to be : (index, [whole grid dataset])\n",
    "    # we need to calculate the indexes which dominate this container\n",
    "    try:\n",
    "        dataList = list(data)\n",
    "        data = dataList[0]\n",
    "\n",
    "        if data and data[1] and data[1][0]:\n",
    "            dimensions = len(data[1][0]) # equal to NSPD\n",
    "            index = data[0]\n",
    "    except:\n",
    "        return []\n",
    "    remainder_array = []\n",
    "    current_position = []\n",
    "    constant_term = []\n",
    "    zero_vector = []\n",
    "    identity_vector = []\n",
    "    for i in range(dimensions):\n",
    "        remainder = floor(index / (NSPD**i)) % NSPD\n",
    "        remainder_array.append(remainder)\n",
    "        current_position.append(remainder)\n",
    "        constant_term.append(NSPD**i)\n",
    "        zero_vector.append(0)\n",
    "        identity_vector.append(1)\n",
    "    all_dominants = []    \n",
    "    filtering_points = []\n",
    "    # remainder_array is the initial position\n",
    "    while True:\n",
    "        dominante = index - np.dot(constant_term,current_position)\n",
    "        # useless code\n",
    "        all_dominants.append(dominante) \n",
    "\n",
    "        # in the case of total domination between grids\n",
    "        if all( np.subtract(remainder_array,current_position) >= identity_vector ) :\n",
    "            for element in packed_sky:\n",
    "                if dominante == element[0]:\n",
    "                    return []\n",
    "        # break condition\n",
    "        if current_position == zero_vector:\n",
    "            break\n",
    "        i = dimensions - 1\n",
    "        while i > -1:\n",
    "            if current_position[i] > 0:\n",
    "                current_position[i] = current_position[i] - 1\n",
    "                j = i + 1\n",
    "                while j < dimensions:\n",
    "                    # reset every other previous dimension up to the i-th attribute (excluded)\n",
    "#                     print('Entered in resetting section: j:' + str(j) + ' remainder[j]:' + str(remainder_array[j]))\n",
    "                    current_position[j] = remainder_array[j]\n",
    "                    j = j + 1\n",
    "                break\n",
    "            i = i - 1\n",
    "    local_sky = sfs_query_serial(data[1], [1,1,1,1,1,1,1,1,1,1])\n",
    "    try:\n",
    "        all_dominants.remove(data[0])\n",
    "    except:\n",
    "        print('Id not present in list of dominants')\n",
    "        \n",
    "    return [(data[0],local_sky, all_dominants)]\n",
    "        \n",
    "def global_skyline_calculation(data, NSPD, packed_sky):\n",
    "    try:\n",
    "        dataList = list(data)\n",
    "        data = dataList[0]\n",
    "        if data and data[1] and data[1][0]:\n",
    "            dimensions = len(data[1][0]) # equal to NSPD\n",
    "            index = data[0]\n",
    "            all_dominants = data[2]\n",
    "    except :\n",
    "        print('Error occurred: ' + str(data))\n",
    "        return []\n",
    "    filtering_points = []\n",
    "    \n",
    "    for dominant in all_dominants:\n",
    "        found = False\n",
    "        for el in packed_sky:\n",
    "            if el[0] == dominant:\n",
    "                filtering_points = filtering_points + el[1] # appends a list of a list of points\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print('Did not find dominant: ' + str(dominant) + '.')\n",
    "    if filtering_points:\n",
    "        result = filter_with_memory(data[1], filtering_points, onlyFilter = True)\n",
    "    else:\n",
    "        result = data[1]\n",
    "    return result\n",
    "    # data is \n",
    "    \n",
    "def grid_containers_all_parallel(dataArray, numSlices = 2):\n",
    "    dimensions = len(dataArray[0])\n",
    "    numSlicesPerDimension = numSlices\n",
    "    weights = [1,1,1,1,1,1,1,1,1,1,1]\n",
    "    print('numSlicesPerDimension: ' + str(numSlicesPerDimension))\n",
    "    print('Number of slices := ' + str(numSlices**dimensions))\n",
    "    numSlices = ceil(numSlices**dimensions)\n",
    "    num__ = min(numSlices,32)\n",
    "    start = time.time()\n",
    "    packed_data = spark.sparkContext.parallelize(dataArray, num__) \\\n",
    "                    .map(lambda x : ( get_grid_partition_index(x,dimensions,numSlicesPerDimension), x ) )  \\\n",
    "                    .partitionBy(numSlices) \\\n",
    "                    .mapPartitions(lambda x : pack_data(x, numSlicesPerDimension)) \\\n",
    "                    .collect()\n",
    "    m2 = spark.sparkContext.parallelize(packed_data, numSlices) \\\n",
    "                    .mapPartitions(lambda x :test_square_domination(x,numSlicesPerDimension,packed_data) )  \\\n",
    "                    .collect()\n",
    "    m3 = spark.sparkContext.parallelize(m2, numSlices) \\\n",
    "                    .mapPartitions(lambda x :global_skyline_calculation(x,numSlicesPerDimension,m2) )  \\\n",
    "                    .collect()\n",
    "    end = time.time() - start\n",
    "    print('Total time for grid all parallel: ' + str(end))\n",
    "    print('Length of global skyline:' + str(len(m3)))\n",
    "    parallel_sky = []\n",
    "    for el in m2:\n",
    "        parallel_sky = parallel_sky + el[1]\n",
    "    print('Length of local skyline:' + str(len(parallel_sky)))\n",
    "    return Result(m3, end)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parallel SFS with Accumulator\n",
    "class VectorListAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self, value):\n",
    "        return []\n",
    "    def addInPlace(self, accuList, newPoints):\n",
    "        values = []\n",
    "        stopFirst = len(newPoints[0])\n",
    "        numDim = stopFirst\n",
    "        stopFirstArray = range(stopFirst)\n",
    "        # non Dom := non dominated list of elements. We replace all elements found in accuList inside nonDom\n",
    "        finList = []\n",
    "        for point in newPoints: # list of new points\n",
    "            add = True\n",
    "            for other in accuList:\n",
    "                # sum of Domination must be == numDim if we dominate the other point\n",
    "                # sum of Domination must be == - numDim if we get dominated by the other point\n",
    "                sumDom = 0\n",
    "                for k in stopFirstArray:\n",
    "                    # if point is better than [the] other[-point]\n",
    "                    if point[k] < other[k] :\n",
    "                        sumDom = sumDom + 1\n",
    "                    else:\n",
    "                        sumDom = sumDom - 1\n",
    "                    if sumDom != k or sumDom != -k:\n",
    "                        # if one point is dominated in one dimension and dominates in another dimension\n",
    "                        # the number sumDom will not be equal to the current iteration 'k'\n",
    "                        break\n",
    "                if sumDom == -numDim:\n",
    "                    add = False\n",
    "                    break\n",
    "                elif sumDom == numDim:\n",
    "                    accuList.remove(other)\n",
    "            if add == True:\n",
    "                finList.append(point)\n",
    "        accuList = accuList + finList\n",
    "        return accuList\n",
    "\n",
    "def accumulator_skyline(dataArray, numSlices = 12):\n",
    "    global vl \n",
    "    vl = spark.sparkContext.accumulator([], WrapperVectorListAccumulatorParam())\n",
    "    print('NumSlices: ' + str(numSlices))\n",
    "    def sky_f(x):\n",
    "        global vl\n",
    "        el_to_pass = list(x)\n",
    "        curr_time = str(time.asctime(time.localtime(time.time())))\n",
    "        vl.add( el_to_pass )\n",
    "    dimensions = len(dataArray[0])\n",
    "    weights = [1,1,1,1,1,1]\n",
    "    start = time.time()\n",
    "    initialResult = spark.sparkContext.parallelize(dataArray, numSlices).sortBy(lambda x: x[0])\\\n",
    "                    .mapPartitions(sfs_query)\\\n",
    "                    .foreachPartition(sky_f)\n",
    "                    \n",
    "    end = time.time()- start\n",
    "    print('Time taken for parallel section in accumulator: ' + str(end))\n",
    "    print('Accumulator Length of initial Pass is :' + str(len(vl.value)))\n",
    "    print('Accumulator Length of the skyline is :' + str(len(vl.value)))\n",
    "    print('Total Time: ' + str(end))\n",
    "    return Result(vl.value,end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def helperVisualFunct(data, title = None, xlabel = None, ylabel = None, marker = '.', label = '', reverseOrder = False, linestyle='Empty', linewidth= 'Empty'):\n",
    "    plt.axes(projection=None)\n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "    if xlabel != None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel != None:\n",
    "        plt.xlabel(ylabel)\n",
    "    splt = splitXAndY(data)\n",
    "    if linestyle == 'Empty':\n",
    "        if not reverseOrder:\n",
    "            plt.plot(splt[0],splt[1], marker = marker, label = label)\n",
    "        else: \n",
    "            plt.plot(splt[1],splt[0], marker = marker, label = label)\n",
    "    else:\n",
    "        if not reverseOrder:\n",
    "            plt.plot(splt[0],splt[1], marker = marker, label = label, linestyle = linestyle, linewidth = linewidth)\n",
    "        else: \n",
    "            plt.plot(splt[1],splt[0], marker = marker, label = label, linestyle = linestyle, linewidth = linewidth)\n",
    "    \n",
    "def show3D(data):\n",
    "    randData = data\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    multiDimensionalData = splitXAndY(randData)\n",
    "    plt.scatter(multiDimensionalData[0], multiDimensionalData[1], multiDimensionalData[2],marker='x');\n",
    "\n",
    "def show3DList(dataAsList):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    first = True\n",
    "    color_map = plt.get_cmap('Reds')\n",
    "    for data in dataAsList:\n",
    "        multiDimensionalData = splitXAndY(data[0:400000])\n",
    "        color_array = []\n",
    "        size_array = []\n",
    "        for i in range(len(multiDimensionalData[0])):\n",
    "            color_array.append(multiDimensionalData[0][i] + multiDimensionalData[1][i] + multiDimensionalData[2][i]) \n",
    "\n",
    "        scatter_plot = plt.scatter(multiDimensionalData[0], multiDimensionalData[1], multiDimensionalData[2],\\\n",
    "                    marker='o',c=color_array,cmap = color_map)\n",
    "\n",
    "    plt.colorbar(scatter_plot)\n",
    "\n",
    "    \n",
    "\n",
    "def mydatabase(dp = 10, randomize = False ):\n",
    "    \n",
    "    if (randomize == False and dp <= 10): return [(350,190), (400, 250), (320, 500), (430, 140), (550, 130),\n",
    "                           (360, 420), (580, 500), (410, 600), (330, 210), (210, 400)]\n",
    "    # cost and distance\n",
    "    minimumCost = 350 # [$/week]\n",
    "    minimumDistance = 147 # [m]    xopt = (minimumCost, minimumDistance) # Optimal choice\n",
    "    skyline = [(350, 190), (330, 210), (430, 140), (210, 400), (550, 130)]\n",
    "    allPoints = [(350,190), (400, 250), (320, 500), (430, 140), (550, 130),\n",
    "                           (360, 420), (580, 500), (410, 600), (330, 210), (210, 400)]\n",
    "    choice = 0\n",
    "    for i in range(dp-10):\n",
    "        if choice == 0:\n",
    "            x = skyline[i%5][0] + i + 1\n",
    "            y = skyline[i%5][1] + 1\n",
    "            choice = 1\n",
    "        elif choice == 1:\n",
    "            x = skyline[i%5][0] + i + 1\n",
    "            y = skyline[i%5][1] + i + 1 \n",
    "            choice = 2\n",
    "        else :\n",
    "            x = skyline[i%5][0] + 1\n",
    "            y = skyline[i%5][1] + i + 1\n",
    "            choice = 0\n",
    "        no = (x,y)\n",
    "        allPoints.append(no)\n",
    "    return allPoints\n",
    "\n",
    "def splitXAndY(db):\n",
    "    x = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    if isinstance(db, list):\n",
    "        el = len(db)\n",
    "        for i in range(len(db[0])) :\n",
    "            for j in range(el) :\n",
    "                try:\n",
    "                    x[i].append(db[j][i])\n",
    "                except:\n",
    "                    print('Element is: ' + str(el) + ', j is: ' + str(j) + ', i is:' + str(i))\n",
    "#                 x[i].append(db[i][i])\n",
    "    else :\n",
    "        el = int(db.size/db[0].size)\n",
    "        for i in range(db[0].size) :\n",
    "            for j in range(el) :\n",
    "                x[i].append(db[j][i])\n",
    "    return x  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real datasets\n",
    "######## Reading from local CSV\n",
    "def get_CSV_Few_SkyPoints(num_col = 4):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(\"household_power_consumption.txt\", delimiter= ';')\n",
    "    print( type(data))\n",
    "    print(len(data))\n",
    "    # column 0 and 1 are date and time\n",
    "    col_to_drop = [0, 1, 6, 7, 8, 2, 4]\n",
    "    if num_col > 7:\n",
    "        print('Warning: Dataset only contains 7 columns')\n",
    "        num_col = 7\n",
    "    if num_col < 2:\n",
    "        print('Warning: Minimum number of columns in the dataset is 2')\n",
    "        num_col = 2\n",
    "    num_col_to_drop = 2 + (7-num_col) # if we want only 4 columns, we drop 5 out of 9 columns.\n",
    "                                      # if we want 6 columns \n",
    "    ### No duplicates in the data\n",
    "    data_drop_column = data.drop(data.columns[ col_to_drop[:num_col_to_drop] ], axis=1)\n",
    "    data_drop_column = data_drop_column.drop_duplicates()\n",
    "    # Only 1.9M unique values instead of 2.07M\n",
    "    data_drop_column = data_drop_column.apply(pd.to_numeric, errors='coerce')\n",
    "    data_drop_column = data_drop_column.dropna(axis=0, how='any')\n",
    "    for column in data_drop_column.columns:\n",
    "        data_drop_column[column] = pd.to_numeric(data_drop_column[column])\n",
    "    data_as_list = data_drop_column.values.tolist()\n",
    "    data_as_list[0:10]\n",
    "    type(data_as_list[0][0])\n",
    "    return data_as_list\n",
    "\n",
    "def get_CSV_Many_SkyPoints(num_col = 4, debug = False):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(\"HT_Sensor_dataset.dat\", delimiter= ';')\n",
    "    # column 0 and 1 are date and time\n",
    "    col_to_drop = [0, 1, 12, 2,3,4,5,6,7,8,9,10,11]\n",
    "    if num_col > 10:\n",
    "        print('Warning: Dataset only contains 10 columns')\n",
    "        num_col = 10\n",
    "    if num_col < 2:\n",
    "        print('Warning: Minimum number of columns in the dataset is 2')\n",
    "        num_col = 2\n",
    "    num_col_to_drop = 3 + (10-num_col) \n",
    "    ### No duplicates in the data\n",
    "    data_drop_column = data.drop(data.columns[ col_to_drop[:num_col_to_drop] ], axis=1)\n",
    "    data_drop_column = data_drop_column.drop_duplicates()\n",
    "    # Only .92M unique values\n",
    "    data_drop_column = data_drop_column.apply(pd.to_numeric, errors='coerce')\n",
    "    data_drop_column = data_drop_column.dropna(axis=0, how='any')\n",
    "    for column in data_drop_column.columns:\n",
    "        data_drop_column[column] = pd.to_numeric(data_drop_column[column])\n",
    "    data_as_list = data_drop_column.values.tolist()\n",
    "    data_as_list[0:10]\n",
    "    if debug: \n",
    "        print( type(data))\n",
    "        print(data[:10])\n",
    "        print(len(data))\n",
    "        print('data after drop')\n",
    "        print(data_drop_column[:10])\n",
    "        type(data_as_list[0][0])\n",
    "    return data_as_list\n",
    "\n",
    "# data_from_csv = get_CSV_Many_SkyPoints(6)\n",
    "# data_from_csv_norm = normalize_data(data_from_csv).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumSlices: 16\n",
      "Length of first pass of parallel sfs is: 5358\n",
      "Time taken by the parallel section of SFS: 37.442527055740356\n",
      "Length of the skyline: 4629\n",
      "Time taken by the serial section of SFS: 2.54007625579834\n",
      "Time taken in total for SFS execution: 39.982603311538696\n",
      "NumSlices: 16\n",
      "Length of first pass of parallel sfs is: 17986\n",
      "Time taken by the parallel section of SFS: 54.88599920272827\n",
      "Length of the skyline: 16578\n",
      "Time taken by the serial section of SFS: 31.516130447387695\n",
      "Time taken in total for SFS execution: 86.40212965011597\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEOCAYAAACKDawAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwTElEQVR4nO3deVxU9f7H8Re7OAPumiaoqCguKOCaaKkpLa6oKBTlL9Nb3ehmi5C7mZa3NEuzrl5vdSkxLlhqZpZp4oKmo4IiuOACuKKgMoMzAzPn90c3lJu4sB1gPs/Ho8ejORzOfL4fhreHMzOfsVMURUEIIUSNZ692AUIIISqHBL4QQtgICXwhhLAREvhCCGEjJPCFEMJGSOALIYSNkMAXVUZWVhY+Pj4MHz686L9hw4YRFxd31++dNm0au3btuuM+mZmZRERE3FdN93Lce5GVlYWfn1+p9o+JiWH58uVlrkEIR7ULEOJWtWrVYu3atUW3L168yJAhQ+jUqRPt27cv8fvmzZt312OfO3eOU6dO3Vc993LcihYaGqp2CaKGkDN8UaU1adKEFi1acPr0aQA++eQTnnjiCYYOHcorr7xCdnY2AOHh4fz4449kZWXx6KOPMnfuXEaPHs3gwYP5+eefsVgsTJ8+nYyMDCZMmEBhYSGzZs1i6NChBAcH88orr2AwGP50/3c77v+6l+Omp6czYMAAfv75Zz799FNef/31oq/t27ePESNGFNt/yZIlvP322wAMGDCAJUuWEBYWRv/+/Vm8eHHRflu2bGHMmDGMGDGCcePGceDAgdK0XNRgEviiSjtw4AAZGRl06dKF+Ph4tm/fTlxcHOvXr6dt27ZERUX96XsyMzMJDAwkLi6O119/nfnz5+Pg4MA777yDp6cnK1eu5ODBg/z222+sW7eONWvW4OHhwdGjR+9Yy+2O+7/udtxjx47xwgsvMG/ePAYNGkRISAi//vorV69eBSA2NpZx48bdsY78/HxWrVrF6tWr+de//kVmZianT5/mww8/ZPny5Xz33XfMnTuXiIgI8vPz76HLwlbIJR1RpRiNRoYPHw6AxWKhXr16vP/++zRt2pSEhASCg4OpXbs2AM888wyfffYZZrO52DGcnJx4+OGHAejQoUNRmN7K29sbBwcHxowZQ2BgIEFBQfj6+t6xtrIcNysrC7PZzDPPPEOPHj3o3bs3AA0aNOCRRx5h7dq1jBgxgh07djBr1ixyc3NLrGPgwIHA73/9NGjQgGvXrpGUlMSlS5cYP3580X52dnZkZGTc8VKYsC0S+KJK+d9r+LeyWq3Y2dkVu11YWPin/ZycnLC3//2P11v3v5W7uztr165l//797N69m1dffZUJEybw1FNPlVhbWY77xz8Un3zyCVOmTGHTpk0EBQUB8NRTTzF79mwcHR0ZPHgwGo3mjoHv4uJS9P92dnYoioLVaqV3797FLvGcP3+exo0bl3gcYXvkko6oNvr27Ut8fHzRZYro6Gi6d++Os7PzPX2/g4MDBQUFAGzdupXx48fj5+dHREQEI0aM4PDhw2Wu8U7HdXZ2JiAggPnz5zN79uyi5x/8/f2xt7dn5cqVd72cU5LevXuzc+dO0tPTAdi2bRvDhg3DaDSWeU2i5pAzfFFtjB49mvPnzzNmzBisVistWrTggw8+uOfvb9OmDS4uLowePZpvvvmGhIQEhgwZQu3atalTpw5z584tc439+vW763F79uzJk08+ydSpU1mxYgUAwcHB/PDDD6W+/NKmTRvefvttXnvtNRRFwdHRkU8//RSNRlPmNYmaw07GIwuhrsLCQl5++WWGDRvGE088oXY5ogaTSzpCqOjEiRP07t2bevXq8dhjj6ldjqjh5AxfCCFshJzhCyGEjZDAF0IIGyGBL4QQNqJKvyxTp9OpXYIQQlRLAQEBf9pWpQMfbl90dZKamoqPj4/aZVQJ0ovipB/FST9uKmsvSjpZlks6QghhIyTwhRDCRkjgCyGEjZDAF0IIGyGBL4QQNkICXwghbIQEvhBCVCG6M7l8cygX3ZmSPwSntCTwhRCiith54jIh/0jki/25PLVid7mHvgS+EEJUAduPZ/PiVzos1t8HGBdYrOw+eaVc76PKv9NWCCFqsmv5Bbyz4Qj/0WXRrG4tjAVWCq1WnBzt6eXVoFzvSwJfCCFU8uPh88xYm0KOwcxLj7TmlYFtSTl3nfV7Uhna04eAFvXK9f4k8IUQopJdyjMya20KGw9foENTdz4f351OD9YBIKBFPWrn18OnnMMeJPCFEKLSKIpC/P6zzP3+CDcKLLwZ1I5J/bxwcqicp1Ml8IUQohJk5eYz9dvDJBzLpluLerw3ypc2jbWVWsM9/bOSlJREeHg4AFeuXOHFF1/kqaeeYty4cWRkZAAQGxtLcHAwISEhbN26FQCj0UhERARhYWFMnDiRnJwcAA4ePMiYMWMYN24cS5curYh1CSFElWC1Kny56zSDP0xg3+kc5gzrSOxfeld62MM9nOGvWLGCdevW4erqCsD777/P0KFDeeKJJ9i9ezcnT57E1dWV6Oho4uPjMZlMhIWF0adPH2JiYvD29iYiIoINGzawbNkypk+fzqxZs1iyZAkeHh5MmjSJlJQUOnbsWOGLFUKIypSerScyLpl9Z3Lp592I+SM70bxebdXquesZvqenJ0uWLCm6vX//fi5evMj48eNZv349PXr0IDk5GT8/P5ydnXFzc8PT05O0tDR0Oh19+/YFoF+/fiQmJqLX6zGbzXh6emJnZ0dgYCCJiYkVt0IhhKhkBRYrn2w9weMfbef4JT0Lx3Thy//rrmrYwz2c4QcFBZGVlVV0++zZs7i7u/PFF1+wdOlSVqxYQcuWLXFzcyvaR6PRoNfr0ev1Rds1Gg15eXno9Xq0Wm2xfTMzM0u8/9TU1FItrKowGo3Vfg3lRXpRnPSjuJrSjxNXTHy4K5uTOWYCW2h4qWcD6rnmkZaWds/HqKhe3PeTtnXr1mXAgAEADBgwgA8//JBOnTphMBiK9jEYDLi5uaHVaou2GwwG3N3di227dXtJqvtHnsnHtt0kvShO+lFcde+HscDCR78cZ3nCOeprnPnsaX8e69S0VMeqMh9xGBAQwLZt2wDYu3cvbdq0wdfXF51Oh8lkIi8vj/T0dLy9vfH39y/aNyEhgYCAALRaLU5OTmRkZKAoCjt27KBbt26lXpgQQqht7+kcnvhoO5/+mk6w34NsnvxwqcO+It33GX5kZCTTp09n9erVaLVaFi5cSJ06dQgPDycsLAxFUZg8eTIuLi6EhoYSGRlJaGgoTk5OLFy4EIA5c+bwxhtvYLFYCAwMpEuXLuW+MCGEqGh6UyF//zGNfyeeoXk9V6In9KBv20Zql1UiO0VRFLWLKIlOpyMgIEDtMsqkuv+ZWp6kF8VJP4qrbv3YdiybqWsOce7aDcY/1JI3BrdD41I+b20qj0s6t8tOeeOVEELch1yDmbkbjrBm/1naNNYS98JD5T7zpqJI4AshxD1QFIWNhy8wc+1hruYXEDGgDS8PaIOLo4Papd0zCXwhhLiLS9eNzFh7mE0pF+n8YB3+/VxPOjQr+dWFVZUEvhBClEBRFP6jy+Kd749gKrQS9Xh7ng9shWMlDTsrbxL4QghxG5k5+by15hA7TlymR8v6vDeqM16NKn/+TXmSwBdCiFtYrAr/TjzN3388ioO9HXNHdOKpHp7Y29upXVqZSeALIcR/Hb+YR2R8MvszrvJIu0bMH9mZZnVd1S6r3EjgCyFsXoHFyme/prNkywk0Lg4sHtuV4V2bYWdX/c/qbyWBL4SwaYeyrvFmXBJpF/IY4tuU2cM60lDronZZFUICXwhhk4wFFj7cfIwVCSdpqHVheXgAgzs+oHZZFUoCXwhhc/acvELUmkOcumxgXHcP3nrChzquTmqXVeEk8IUQNiPPWMCCH9P4ancGnvVr8/XzPenTpqHaZVUaCXwhhE3YmnaJqd8e4uJ1I88HtuK1wd7UdratCLSt1QohbE6Owczb61P47uA52jbWsuzFh/DzrB7DzsqbBL4QokZSFIXvk88ze10K124U8LeBbXmpf+tqNeysvEngCyFqnIvXjUz79jCbUy/i27wOX0/sSfsHqt+ws/ImgS+EqDEUReGbvZnM+yEVc6GVaU/48H99WlbbYWflTQJfCFEjZFzJJ2pNMrvSr9DLqz7vBfvSsqFG7bKqFAl8IUS1ZrEqfL7zFB/8dBQne3vmj+zMuO4eNWLYWXmTwBdCVFtHL+QxJT6ZpMyrDGzfmHdGdqJpnZoz7Ky8SeALIaodc6GVZb+e4JOtJ3Cr5cRH47oyrEvNG3ZW3iTwhRDVSlLmVabEJXP0Yh7DuzZj5pAONKihw87KmwS+EKJauGG2sOjno6zccYrGbrX45zPdeLRDE7XLqlYk8IUQVd6u9Mu8teYQZ67kE9bTk6jH2+Neq+YPOytvEvhCiCrrurGAd39II+a3DFo0qE3MxF70bt1A7bKqrXt6N0JSUhLh4eHFtq1fv56xY8cW3Y6NjSU4OJiQkBC2bt0KgNFoJCIigrCwMCZOnEhOTg4ABw8eZMyYMYwbN46lS5eW11qEEDXI5iMXGbRoG9/szWBSPy9+/Fs/CfsyuusZ/ooVK1i3bh2urjdf6pSamkpcXByKogCQnZ1NdHQ08fHxmEwmwsLC6NOnDzExMXh7exMREcGGDRtYtmwZ06dPZ9asWSxZsgQPDw8mTZpESkoKHTt2rLhVCiGqjSt6E3PWH2Fd0jnaP+DG8vBudPGoq3ZZNcJdz/A9PT1ZsmRJ0e3c3Fw++OADpk6dWrQtOTkZPz8/nJ2dcXNzw9PTk7S0NHQ6HX379gWgX79+JCYmotfrMZvNeHp6YmdnR2BgIImJiRWwNCFEdaIoCmsPnuXRRdvYePg8kx/1Zt3LgRL25eiuZ/hBQUFkZWUBYLFYmDZtGlOnTsXF5ebLoPR6PW5ubkW3NRoNer2+2HaNRkNeXh56vR6tVlts38zMzBLvPzU19f5XVYUYjcZqv4byIr0oTvpxU7ahkI93XWTfuVO0a+jCu48+SIt6haQfP6p2aaqoqMfGfT1pm5KSwpkzZ5g9ezYmk4kTJ04wb948evXqhcFgKNrPYDDg5uaGVqst2m4wGHB3dy+27dbtJfHx8bnfNVUpqamp1X4N5UV6UZz0A6xWhZi9Gbz7QxoFFgszhnRg/EMtcbDxsQhlfWzodLrbbr+vwPf19WXDhg0AZGVl8dprrzFt2jSys7NZvHgxJpMJs9lMeno63t7e+Pv7s23bNnx9fUlISCAgIACtVouTkxMZGRl4eHiwY8cOXn755VIvTAhRPZ26bCAqPpk9p3Lo06YBE3xrM6BHK7XLqtHK5WWZjRo1Ijw8nLCwMBRFYfLkybi4uBAaGkpkZCShoaE4OTmxcOFCAObMmcMbb7yBxWIhMDCQLl26lEcZQohqoNBi5V87T7Hwp2M4O9qzYFRnQrp5kJaWpnZpNZ6d8sdLbaognU5HQECA2mWUifzZfpP0ojhb7Efq+etExieTnHWNQR2a8M6ITjRxr/X712ywHyUpj0s6t8tOeeOVEKLCmQotfLI1nWVbT1DH1YmlYX482bmpDDurZBL4QogKtT8jl8i4ZI5f0jPS70FmDulAPY2z2mXZJAl8IUSFyDcXsvCnY/xr5ymautfi8/Hd6d++sdpl2TQJfCFEudt54jJRa5LJzLlBeK8WTHmsHW4y7Ex1EvhCiHJz7UYB8zek8s2+TFo11PDNpF709JL5N1WFBL4Qolz8lHKB6d8d5orBzAsPt+bVR9tSy8lB7bLELSTwhRBlkp1nYvb6FDYkn8enqTsrn+1O5+Z11C5L3IYEvhCiVBRF4buDZ5mz/gj5JgtvDPbmLw+3xsnhnqauCxVI4Ash7tvZqzeY9u0hfj2ajb9nXf4+2pc2jd3u/o1CVRL4Qoh7ZrUqfL3nDO9tTEMBZg/tQHhvGXZWXUjgCyHuyclsPVHxh/jtdA592zZk/sjOeNSvrXZZ4j5I4Ash7qjQYmXF9lN8uPkYtRzteX+0L6MDmstYhGpIAl8IUaIj564zJT6Jw2evE9SxCXOHd6Lxf4ediepHAl8I8SfGAgtLt5zgs23p1K3tzKdP+fN456ZqlyXKSAJfCFGM7kwOU+KSSc82MMq/OTOG+FC3tgw7qwkk8IUQABhMhby/6ShfJp6mWR1XvnyuBw97N1K7LFGOJPCFECQcy+atNYc4d+0Gz/RqwZuPtUfrIvFQ08hPVAgbdi2/gLkbjhCny8KrkYbYv/Sme8v6apclKogEvhA26sfD55mxNoUcg5mXHmnNKwNl2FlNJ4EvhI25lGdk1toUNh6+QIem7nw+vjudHpRhZ7ZAAl8IG6EoCvH7zzL3+yPcKLDwZlA7JvXzkmFnNkQCXwgbkJmTz9RvD7H9+GW6tajHe6N8adNYq3ZZopJJ4AtRg1mtCv9OPM3fNx3FDnh7eEee7tkCexl2ZpMk8IWooU5c0hMVn8y+M7n0827E/JGdaF5Php3ZMgl8IWqYAouV5Qkn+WjzcVydHVg4pgvB/g/KsDPBPT1bk5SURHh4OACpqamEhYURHh7OhAkTuHz5MgCxsbEEBwcTEhLC1q1bATAajURERBAWFsbEiRPJyckB4ODBg4wZM4Zx48axdOnSiliXEDbp8NlrDF+6k/c3HeXRDo3Z/NrDjJLJluK/7hr4K1asYPr06ZhMJgDmzZvHjBkziI6OZtCgQaxYsYLs7Gyio6NZvXo1K1euZNGiRZjNZmJiYvD29mbVqlWMGDGCZcuWATBr1iwWLlxITEwMSUlJpKSkVOwqhajhjAUWFvyYxvBPdpKtN/HZ0/4seyqARm4uapcmqpC7Br6npydLliwpur1o0SJ8fHwAsFgsuLi4kJycjJ+fH87Ozri5ueHp6UlaWho6nY6+ffsC0K9fPxITE9Hr9ZjNZjw9PbGzsyMwMJDExMQKWp4QNd/e0zk88dF2Pv01nVH+D7J58sM81kkmW4o/u+s1/KCgILKysopuN27cGID9+/fz1Vdf8fXXX7N9+3bc3G5+nqVGo0Gv16PX64u2azQa8vLy0Ov1aLXaYvtmZmaWeP+pqan3v6oqxGg0Vvs1lBfpRXFl7Ud+gZUvdDmsP3qdJlpH5g96AL9mzpw7c4Jz5VhnZZHHx00V1YtSPWn7ww8/8Omnn7J8+XLq16+PVqvFYDAUfd1gMODm5lZsu8FgwN3d/bb7uru7l3hff/w1UV2lpqZW+zWUF+lFcWXpx69HLzHth8Ocu3aD/+vTkjcGt0NTzYedyePjprL2QqfT3Xb7fb/Fbu3atXz11VdER0fj4eEBgK+vLzqdDpPJRF5eHunp6Xh7e+Pv78+2bdsASEhIICAgAK1Wi5OTExkZGSiKwo4dO+jWrVupFyaELck1mHkt9iDjP9+Lq7MDcS88xKyhHat92IvKcV+PEovFwrx582jatCkREREAdO/enVdeeYXw8HDCwsJQFIXJkyfj4uJCaGgokZGRhIaG4uTkxMKFCwGYM2cOb7zxBhaLhcDAQLp06VL+KxOiBlEUhR8OXWDWusNczS8gYkAbXh7QBhdHGXYm7t09BX7z5s2JjY0F4LfffrvtPiEhIYSEhBTb5urqyscff/ynfbt27Vp0PCHEnV26bmT6d4f56chFOj9Yh38/15MOzUq+DCpESeTvQCGqKEVR+M++LOZuOIK50Mpbj7dnQmArHGXYmSglCXwhqqDMnHzeWnOIHScu06NVfd4L7oxXIxl2JspGAl+IKsRiVfhy12ne33QUB3s73hnRibAenjLsTJQLCXwhqojjF/OIjE9mf8ZVHmnXiPkjO9OsrqvaZYkaRAJfCJWZC638Y1s6S7acQOPiwOKxXRnetZnMvxHlTgJfCBUlZ11lSlwyaRfyGOLblNnDOtJQK/NvRMWQwBdCBcYCCyv3XWHNkZM0cnNheXgAgzs+oHZZooaTwBeiku0+eYWo+GROX8kntIcHUY/7UMfVSe2yhA2QwBeikuQZC3hvYxpf78nAs35t3h3clNABvmqXJWyIBL4QlWBr2iWmfnuIi9eNPB/YitcGe3Mm/bjaZQkbI4EvRAXKMZh5e30K3x08R9vGWpa9+BB+nvXULkvYKAl8ISqAoiisTz7P7HUpXL9RwN8GtuWl/q1l2JlQlQS+EOXswrXfh51tTr1Il+Z1WDCxJ+0fkGFnQn0S+EKUE0VRWL03k/kbUimwWpn2hA/PBbbCQcYiiCpCAl+IcnDmioGo+EMknrxCL6/6vBfsS8uGGrXLEqIYCXwhysBiVfh85yk++OkoTvb2zB/ZmXHdPWTYmaiSJPCFKKWjF/KYEp9MUuZVBrZvzDsjO9G0jgw7E1WXBL4Q98lcaGXZryf4ZOsJ3Go58dG4rgzrIsPORNUngS/EfTiYeZXIuGSOXsxjeNdmzBzSgQYy7ExUExL4QtyDG2YLi34+ysodp2jsVouVz3ZjoE8TtcsS4r5I4AtxF7vSLxMVf4iMnHzCenoS9Xh73GvJsDNR/UjgC1GC68YC3v0hjZjfMmjRoDYxE3vRu3UDtcsSotQk8IW4jc1HLjLtu0Nk55mY1M+LyY964+osYxFE9SaBL8QtruhNzF5/hPVJ52j/gBvLw7vRxaOu2mUJUS4k8IXg97EI65LOMXtdCnpTIa8N8uaFh1vj7GivdmlClJt7ejQnJSURHh4OwJkzZwgNDSUsLIxZs2ZhtVoBiI2NJTg4mJCQELZu3QqA0WgkIiKCsLAwJk6cSE5ODgAHDx5kzJgxjBs3jqVLl1bEuoS4Z+eu3mDCl/v42+qDtGigYcMrfXllYFsJe1Hj3PURvWLFCqZPn47JZALg3Xff5dVXX2XVqlUoisIvv/xCdnY20dHRrF69mpUrV7Jo0SLMZjMxMTF4e3uzatUqRowYwbJlywCYNWsWCxcuJCYmhqSkJFJSUip2lULchtWq8PWeMwz+MIHE9CvMGNKB+BcfwruJm9qlCVEh7hr4np6eLFmypOh2SkoKPXr0AKBfv37s2rWL5ORk/Pz8cHZ2xs3NDU9PT9LS0tDpdPTt27do38TERPR6PWazGU9PT+zs7AgMDCQxMbGClifE7Z26bCB0xW6mfXuYLh512PRqPybIZEtRw931Gn5QUBBZWVlFtxVFKXoLuUajIS8vD71ej5vbzbMijUaDXq8vtv3WfbVabbF9MzMzy21BQtxJocXKyh2nWPTzMZwd7VkwqjMh3TxkLIKwCff9pK29/c0/CgwGA+7u7mi1WgwGQ7Htbm5uxbbfaV9395I/HCI1NfV+S6xSjEZjtV9DeVG7F6dyTHy46zLHr5jo7VGbv/ZqSIPaBtLS0lSpR+1+VDXSj5sqqhf3HfgdOnRgz5499OzZk4SEBHr16oWvry+LFy/GZDJhNptJT0/H29sbf39/tm3bhq+vLwkJCQQEBKDVanFyciIjIwMPDw927NjByy+/XOL9+fj4lGmBaktNTa32aygvavXCVGjhky0nWPbrOeq4OrE0zI8nOzdV/axeHhvFST9uKmsvdDrdbbffd+BHRkYyY8YMFi1ahJeXF0FBQTg4OBAeHk5YWBiKojB58mRcXFwIDQ0lMjKS0NBQnJycWLhwIQBz5szhjTfewGKxEBgYSJcuXUq9MCHuZH9GLpFxyRy/pCfY70FmDOlAPY2z2mUJoQo7RVEUtYsoiU6nIyAgQO0yykTOWm6qzF7kmwv5YNMxPt91iqbutZgX3Jn+7RpXyn3fK3lsFCf9uKk8zvBvl53yxitR4+w8cZmoNclk5twgvFcLpjzWDjcZdiaEBL6oOa7dKGD+hlS+2ZdJq4YavpnUi55eMuxMiD9I4IsaYVPKBWZ8d5grBjMvPNyaVx9tSy0nGXYmxK0k8EW1lp1nYva6FDYcOo9PU3dWPtudzs3rqF2WEFWSBL6olhRF4dsDZ3n7+yPkmyy8GdSOSf28cHKQ+TdClEQCX1Q7Z6/eYNq3h/j1aDb+nnX5+2hf2jSW+TdC3I0Evqg2/hh29t7GNBRg9tAOhPduKfNvhLhHEviiWkjP1hMVn8ze07n0bduQ+SM741G/ttplCVGtSOCLKq3QYmX59pMs3nycWo72vD/al9EBzVUfiyBEdSSBL6qslHPXiIxP5vDZ6zzW8QHeHt6Rxu611C5LiGpLAl9UOcYCC0u2HOezbSepV9uZT5/y5/HOTdUuS4hqTwJfVCm6MzlMiUsmPdvAKP/mzBjiQ93aMuxMiPIggS+qBIOpkPc3HeXLxNM0q+PKl8/14GHvRmqXJUSNIoEvVJdwLJu31hzi3LUbPNOrBW8+1h6tizw0hShv8lslVHM138w7G1KJ02Xh1UhD7F96071lfbXLEqLGksAXqth46Dwz1qaQm2/mr/1bEzFAhp0JUdEk8EWlupRnZNbaFDYevkDHZu58+Vx3OjaTYWdCVAYJfFEpFEXh5xN5rIxN4EaBhSmPtWNiXxl2JkRlksAXFS4zJ5+p3x5i+/HLdG9Zj/dG+dK6kVbtsoSwORL4osJYrQr/TjzN3zcdxQ54qWcD3hjeE3sZdiaEKiTwRYU4cSmPyPhD6M7k0s+7EfNHdiLvwhkJeyFUJIEvylWBxcryhJN8tPk4tV0cWDimC8H+D2JnZ0fqBbWrE8K2SeCLcnP47DWmxCVz5Px1nuzclNnDOtLIzUXtsoQQ/yWBL8rMWGDho1+OszzhJPU1znz2dACPdXpA7bKEEP9DAl+UyW+ncoiKT+bkZQMh3Zoz7YkO1KntpHZZQojbkMAXpaI3FbJgYxrRu8/QvJ4rX03oSWDbhmqXJYS4g1IFfkFBAVFRUZw9exZ7e3vmzp2Lo6MjUVFR2NnZ0bZtW2bNmoW9vT2xsbGsXr0aR0dHXnzxRfr374/RaOTNN9/kypUraDQaFixYQP36MkOluth69BLT1hzi/HUj/9enJW8MbodGhp0JUeWV6rd027ZtFBYWsnr1anbu3MnixYspKCjg1VdfpWfPnsycOZNffvmFrl27Eh0dTXx8PCaTibCwMPr06UNMTAze3t5ERESwYcMGli1bxvTp08t7baKc5RrMzP3+CGsOnKVNYy1xLzxEQIt6apclhLhHpQr8Vq1aYbFYsFqt6PV6HB0dOXjwID169ACgX79+7Ny5E3t7e/z8/HB2dsbZ2RlPT0/S0tLQ6XQ8//zzRfsuW7as/FYkyp2iKPxw6AKz1h3man4Brwxow18HtMHFUYadCVGdlCrwa9euzdmzZ3n88cfJzc3ls88+Y+/evUUfLK3RaMjLy0Ov1+Pm5lb0fRqNBr1eX2z7H/uWJDU1tTQlVhlGo7FaryEnv5Cluy+TmJlP2wbOzOnfDK/6Vk4eP3bfx6ruvShv0o/ipB83VVQvShX4X3zxBYGBgbz++uucP3+eZ599loKCgqKvGwwG3N3d0Wq1GAyGYtvd3NyKbf9j35L4+PiUpsQqIzU1tVquQVEU/rMvi7kbjmAutPLW4+2ZENgKxzIMO6uuvago0o/ipB83lbUXOp3utttL9dvr7u5edIZep04dCgsL6dChA3v27AEgISGBbt264evri06nw2QykZeXR3p6Ot7e3vj7+7Nt27aifQMCAkpThqggGVfyeXrlHqbEJ+PT1J2Nf+vLXx5uXaawF0Kor1Rn+OPHj2fq1KmEhYVRUFDA5MmT6dSpEzNmzGDRokV4eXkRFBSEg4MD4eHhhIWFoSgKkydPxsXFhdDQUCIjIwkNDcXJyYmFCxeW97pEKVisCl/sOs0Hm47iYG/HOyM6EdbDU+bfCFFDlCrwNRoNH3300Z+2f/XVV3/aFhISQkhISLFtrq6ufPzxx6W5a1FBjl/MY0p8MgcyrtK/XSPmjexMs7quapclhChH8uJpG2cutPLZtnSWbjmBxsWBxWO7Mrxrs6In4IUQNYcEvg1LzrrKlLhk0i7kMbRLM2YN7UBDrQw7E6KmksC3QTfMFhZvPsaK7Sdp5ObCime6MahDE7XLEkJUMAl8G7P75BWi4pM5fSWf0B4eRD3uQx1XGXYmhC2QwLcRecYC3tuYxtd7MvCsX5tVz/fkoTYy7EwIWyKBbwO2pF1k2reHuXjdyPOBrXhtsDe1neVHL4Stkd/6GizHYObt9Sl8d/Ac3k20LHvqIfw8ZdiZELZKAr8GUhSF9cnnmb0uhTxjAX8b2Ja/9m+Ds6O8U1YIWyaBX8NcuGZk+neH2Zx6kS7N67BgdE/aP1DyrCIhhO2QwK8hFEVh9d5M5m9IpcBqZdoTPjwX2AoHGYsghPgvCfwa4MwVA1Hxh0g8eYVeXvV5L9iXlg01apclhKhiJPCrMYtV4fOdp/jgp6M42dvzbnBnxnbzkGFnQojbksCvpo5e+H3YWVLmVR71acw7IzrzQJ1aapclhKjCJPCrGXOhlU+2nmDZrydwq+XEx6F+DPVtKsPOhBB3JYFfjRzMvMqUuCSOXdQzvGszZg3tSH2Ns9plCSGqCQn8auCG2cLCn47yr52naOxWi5XPdmOgjww7E0LcHwn8Km5X+mWi4g+RkZNPWE9Poh5vj3stGXYmhLh/EvhV1HVjAe/+kErMb5m0bFCbmIm96N26gdplCSGqMQn8KmjzkYtM++4Q2Xkm/tLPi1cf9cbV2UHtsoQQ1ZwEfhVyWW9izvojrE86R/sH3FjxTDd8m9dVuywhRA0hgV8FKIrC2oPnmLM+Bb2pkNcGefPCw61l2JkQolxJ4Kvs3NUbTP/uMFvSLtHVoy5/H+2LdxM3tcsSQtRAEvgqsVoVVv2WwXsb07BYFWYM6cD4h1rKsDMhRIWRwFfBqcsGouKT2XMqhz5tGvDuSF88G9RWuywhRA0ngV+JCi1WVu44xaKfj+HsaM/fR/kypltzGYsghKgUpQ78f/zjH2zZsoWCggJCQ0Pp0aMHUVFR2NnZ0bZtW2bNmoW9vT2xsbGsXr0aR0dHXnzxRfr374/RaOTNN9/kypUraDQaFixYQP369ctzXVXOkXPXiYxP5tDZawzq0IR3RnSiibsMOxNCVJ5SvQxkz549HDhwgJiYGKKjo7lw4QLvvvsur776KqtWrUJRFH755Reys7OJjo5m9erVrFy5kkWLFmE2m4mJicHb25tVq1YxYsQIli1bVt7rqjLMFoWFPx1l2NIdnL92g0/C/FkeHiBhL4SodKU6w9+xYwfe3t789a9/Ra/XM2XKFGJjY+nRowcA/fr1Y+fOndjb2+Pn54ezszPOzs54enqSlpaGTqfj+eefL9q3pga+7kwur67PIvNaAcF+DzJjSAfqybAzIYRKShX4ubm5nDt3js8++4ysrCxefPFFFEUpuhat0WjIy8tDr9fj5nbzJYYajQa9Xl9s+x/7liQ1NbU0JarKWGDliwM5rEu9ToPaDrw98AG6N3fhQkY6F9QuTkVGo7Fa/jwrivSjOOnHTRXVi1IFft26dfHy8sLZ2RkvLy9cXFy4cOFmlBkMBtzd3dFqtRgMhmLb3dzcim3/Y9+S+Pj4lKZE1ew4fpmodclk5d4gvFcLhreyo1uXjmqXVSWkpqZWu59nRZJ+FCf9uKmsvdDpdLfdXqpr+AEBAWzfvh1FUbh48SI3btygd+/e7NmzB4CEhAS6deuGr68vOp0Ok8lEXl4e6enpeHt74+/vz7Zt24r2DQgIKOWyqo5rNwqYEpfE0yv34ORgT+xfejN3RCc0zvJuWSFE1VCqM/z+/fuzd+9eRo8ejaIozJw5k+bNmzNjxgwWLVqEl5cXQUFBODg4EB4eTlhYGIqiMHnyZFxcXAgNDSUyMpLQ0FCcnJxYuHBhea+rUm1KucCM7w5zxWDmxUda87eBbanlJMPOhBBVS6lfljllypQ/bfvqq6/+tC0kJISQkJBi21xdXfn4449Le9dVRnaeidnrUthw6Dw+Td1Z+Wx3Ojevo3ZZQghxW/LGq1JQFIU1+8/y9vdHuGG28GZQOyb188LJQS7fCCGqLgn8+3T26g2mrjnEtmPZ+Hv+PuysTWMZdiaEqPok8O+R1arw1Z4zLNiYhgLMHtqB8N4y7EwIUX1I4N+D9Gw9UfHJ7D2dS9+2DZk/sjMe9WXYmRCiepHAv4MCi5UV20+yePNxajna8/5oX0YHyLAzIUT1JIFfgsNnrxEZn0zKues81vEB3h7RkcZuMv9GCFF9SeD/D2OBhSVbjvPZtpPUq+3Mp0/583jnpmqXJYQQZSaBf4t9p3OYEp/MyWwDo/ybM2OID3Vry7AzIUTNIIEPGEyFvL/pKF8mnqZZHVe+fK4HD3s3UrssIYQoVzYf+AnHsnlrzSHOXbvBs71b8mZQOzQuNt8WIUQNZLPJdjXfzDsbUonTZeHVSMN//tKbbi1r9qduCSFsm00G/sZD55mxNoXcfDN/7d+aiAEy7EwIUfPZVOBfum5k5toUfky5QMdm7nz5XHc6NpNhZ0II22ATga8oCnG6LOZ+fwRjoZUpj7VjYl8ZdiaEsC01PvAzc/KZ+u0hth+/TPeW9XhvlC+tG2nVLksIISpdjQx83ZlcEtMvk2swE7M3Eztg7vCOPNWzBfYy7EwIYaNqXODrzuQStmI3pkIrAF096rI0zI/m9WTYmRDCttW4i9i7T17B/N+wt7ODQR0aS9gLIQQ1MPB7eTXAxckeBztwcbSnl1dDtUsSQogqocZd0gloUY+vn+/F7pNX6OXVgIAW9dQuSQghqoQaF/jwe+hL0AshRHE17pKOEEKI25PAF0IIGyGBL4QQNkICXwghbIQEvhBC2AgJfCGEsBF2iqIoahdREp1Op3YJQghRLQUEBPxpW5UOfCGEEOVHLukIIYSNkMAXQggbIYFfDqxWKzNnzmTs2LGEh4dz5syZYl///vvvGTNmDOPGjWPmzJlYrVaVKq0cd+vHH2bMmMEHH3xQydVVvrv1Izk5mbCwMEJDQ3nllVcwmUwqVVrx7taLdevWMXLkSEaNGsWqVatUqrLyJSUlER4e/qftW7ZsYdSoUYwdO5bY2Niy35EiymzTpk1KZGSkoiiKcuDAAeWFF14o+tqNGzeUgQMHKvn5+YqiKMrkyZOVzZs3q1JnZblTP/4QExOjhISEKO+//35ll1fp7tQPq9WqDBs2TDl9+rSiKIoSGxurpKenq1JnZbjbY6NPnz5Kbm6uYjKZlEcffVS5evWqGmVWquXLlytDhgxRxowZU2y72Wwu6oHJZFKCg4OVS5culem+5Ay/HOh0Ovr27QtA165dOXz4cNHXnJ2dWb16Na6urgAUFhbi4uKiSp2V5U79ADhw4ABJSUmMHTtWjfIq3Z36cerUKerWrcuXX37J008/zdWrV/Hy8lKr1Ap3t8dGu3btyMvLw2w2oygKdnY1/xPqPD09WbJkyZ+2p6en4+npSZ06dXB2diYgIIB9+/aV6b4k8MuBXq9Hq735ObkODg4UFhYCYG9vT8OGv8/kj46OJj8/nz59+qhSZ2W5Uz8uXbrE0qVLmTlzplrlVbo79SM3N5cDBw4QFhbG559/zu7du0lMTFSr1Ap3p14AtG3bllGjRvHkk0/yyCOP4O7urkaZlSooKAhHxz8PLtbr9bi5uRXd1mg06PX6Mt2XBH450Gq1GAyGottWq7XYD9BqtbJgwQJ27tzJkiVLavxZy5368eOPP5Kbm8ukSZNYvnw533//PWvWrFGr1Epxp37UrVuXFi1a0KZNG5ycnOjbt++fznprkjv1Ii0tjV9//ZVffvmFLVu2kJOTw8aNG9UqVXX/2yuDwVDsH4DSkMAvB/7+/iQkJABw8OBBvL29i3195syZmEwmli1bVnRppya7Uz+eeeYZ1qxZQ3R0NJMmTWLIkCEEBwerVWqluFM/PDw8MBgMRU9e7tu3j7Zt26pSZ2W4Uy/c3NyoVasWLi4uODg4UL9+fa5fv65Wqapr3bo1Z86c4erVq5jNZvbt24efn1+ZjlkjPwClsg0aNIidO3cybtw4FEVh/vz5rF+/nvz8fDp16kRcXBzdunXj2WefBX4PvUGDBqlcdcW5Uz9s5br9re7Wj3nz5vH666+jKAp+fn488sgjapdcYe7Wi7FjxxIWFoaTkxOenp6MHDlS7ZIr3a39iIqKYsKECSiKwqhRo2jSpEmZji3vtBVCCBshl3SEEMJGSOALIYSNkMAXQggbIYEvhBA2QgJfCCGqoJLm69xqzZo1jBkzhuDgYD755JO7HlNelimEEFXMihUrWLdu3R3ft5ORkUFMTAzR0dE4Ozvz8ccfU1BQgJOTU4nfI2f4QghRxfzvfJ2jR48SHh5OeHg4ERER5OXlsWvXLjp16kRkZCRPP/00/v7+dwx7kDN8IYSocoKCgsjKyiq6PWPGDObPn0+bNm34z3/+wz//+U9q1arFvn37iImJwWQyERoaSlxc3B3nD0ngCyFEFZeens6cOXMAKCgooFWrVvj6+tKjRw+0Wi1arZbWrVtz+vRpfH19SzyOBL4QQlRxrVq1YsGCBTRr1gydTkd2djatWrVi1apVmEwmLBZL0TjlO5HAF0KIKm727NlERkZisVgAmDdvHq1atWLUqFGEhoaiKAovvfQSdevWveNxZJaOEELYCHmVjhBC2AgJfCGEsBES+EIIYSMk8IUQwkZI4AshhI2QwBdCCBshgS+EEDZCAl8IIWzE/wNHZL7kbLSZQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numDim = 4\n",
    "numDataArray = [1*10**5,1*10**6]\n",
    "\n",
    "tuplesInSkyline = []\n",
    "numDataSkyline = []\n",
    "timeTakenForCalculation = []\n",
    "for numData in numDataArray:\n",
    "    dataConfig = DataGenConfig(numberOfData = numData, typeOfCorrelation=DataGenEnum.antiCorrelated, numberOfDimensions = numDim,dataRange = [0,1],  spreadPercentage = 100)\n",
    "    dataArray = dataGenerator(dataConfig)\n",
    "    datapoints = normalize_data(dataArray).tolist()\n",
    "    dataArray = []\n",
    "    # Example with one-dimensional slicing Parallel SFS\n",
    "    sp = parallel_sfs(datapoints, 16)\n",
    "    # print('~~~~~~~~~~~~~~~~~')\n",
    "    # spwr = parallel_sfs_with_representatives(datapoints, 8)\n",
    "    numDataSkyline.append( (len(sp.resultList), numData) )\n",
    "    timeTakenForCalculation.append( (sp.timeTaken, numData) )\n",
    "    \n",
    "helperVisualFunct(numDataSkyline, title = 'Points in skyline', reverseOrder = True)\n",
    "plt.show()\n",
    "helperVisualFunct(timeTakenForCalculation, title = 'Time in skyline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices for representative skyline 16\n",
      "Time taken to find best reps 4.918620824813843\n",
      "Length of representatives: 111\n",
      "Length of representatives after skyline query: 107\n",
      "Time taken to filter: 15.965808153152466\n",
      "Length of the after filter: 366459\n",
      "Time taken to find the local skylines: 26.20270276069641\n",
      "Length of parallel skyline: 25511\n",
      "Final Serial stage:\n",
      "~~~~~ Time taken to find the global skyline : 72.7003538608551\n",
      "~~~~~ Length of the skyline: 24265\n",
      "~~~~~ Total time taken with representatives: 119.78748559951782\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numDim = 4\n",
    "tuplesInSkyline = []\n",
    "numDataArray = [2*10**6]\n",
    "numDataSkyline = []\n",
    "timeTakenForCalculation = []\n",
    "for numData in numDataArray:\n",
    "    dataConfig = DataGenConfig(numberOfData = numData, typeOfCorrelation=DataGenEnum.antiCorrelated, numberOfDimensions = numDim,dataRange = [0,1],  spreadPercentage = 100)\n",
    "    dataArray = dataGenerator(dataConfig)\n",
    "    datapoints = normalize_data(dataArray).tolist()\n",
    "    dataArray = []\n",
    "    # Example with one-dimensional slicing Parallel SFS with Representative filtering\n",
    "    spwr = parallel_sfs_with_representatives(datapoints, 16)\n",
    "    numDataSkyline.append( (len(spwr.resultList), numData) )\n",
    "    timeTakenForCalculation.append( (spwr.timeTaken, numData) )\n",
    "    \n",
    "helperVisualFunct(numDataSkyline, title = 'Points in skyline', reverseOrder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_algorithms():\n",
    "    # To test the algorithm on a real dataset just use one of the two CSV loading methods\n",
    "    dataset = get_CSV_Many_SkyPoints(num_col = 2, debug = True)\n",
    "    datapoints = normalize_data(dataset)\n",
    "    \n",
    "\n",
    "    # We can use one of the following commented algorithms\n",
    "    # Slice on the first dimension and equally partition all data\n",
    "    parallel_sfs(dataset)\n",
    "    # Execute BNL on all partitions (dataset is randomly partitioned)\n",
    "    parallel_bnl(dataset)\n",
    "    # Same as above but executes SFS\n",
    "    parallel_sfs_random(dataset)\n",
    "\n",
    "    # Naive grid partitioning\n",
    "    naive_grid_partitioning(dataset)\n",
    "    # Grid partitioning with reduction of test dominations (similar to MR-Sketch and MR-DDT)\n",
    "    grid_containers_all_parallel(dataset)\n",
    "\n",
    "    # Naive angle partitioning \n",
    "    parallel_angled_partitioning(dataset)\n",
    "\n",
    "    # Naive angle partitioning but first we find the local skyline within a radius and passes these data to the angled partitioning method\n",
    "    # with the goal of increasing the accuracy of the dataset\n",
    "    parallel_radius_partitioning(dataset)\n",
    "\n",
    "    ####### Slice on the first dimension like parallel_sfs with an added filtering phase before all other computations\n",
    "    # # The filtering phase here groups points into a squares in a grid and all squares that are dominated by a point within another grid, are removed.\n",
    "    # # As such, for lower dimensionalities or for independent datasets, the number of test dominations is lowered substantially.\n",
    "    sfs_index_squares(dataset)\n",
    "    # # The filtering phase here finds a few points with a big domination area (usually at most 100 points work well)\n",
    "    # # which then test for domination against all other tuples in the dataset\n",
    "    parallel_sfs_with_representatives(dataset)\n",
    "\n",
    "    # This is just a parallel SFS algorithm in which in the global calculation of the skyline is carried through a parallel structure called accumulator\n",
    "    # In practice it works as good as a serial computation, because accumulators are used mainly for debugging purposes \n",
    "    accumulator_skyline(dataset)\n",
    "    # The same as above but by using pyspark's parallelize method\n",
    "    parallel_3P(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddb1c596ab3cd0c90578027eaf8d340959d24852b0a21e09fa6e8d6d8186ce97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
